# Konflikt-Dokumentation - Pipeline 2

**Analyst**: agata-van-data
**Datum**: 2025-11-14
**Scope**: Cross-Reference zwischen ARCHITEKTUR.md, Risikomanagement-Logik.md, docker-compose.yml, copilot-instructions.md

---

## 1. Validierte Konflikte (aus Hypothesen)

### ‚úÖ Konflikt 1: Service-Namens-Dualit√§t

**Status**: BEST√ÑTIGT

**Quellen**:
- docker-compose.yml: Container-Name `cdb_core` (Zeile 166-196)
- ARCHITEKTUR.md: Service als "Signal Engine" bezeichnet (Tabelle Abschnitt 3)
- docker-compose.yml: Aliasing `signal_engine` im Network (Zeile 195-196)

**Konflikt**: Inkonsistente Benennung - Container hei√üt `cdb_core`, aber DNS-Alias und Dokumentation verwenden `signal_engine`.

**Auswirkung**: Verwirrung beim Debugging (`docker ps` zeigt `cdb_core`, Logs referenzieren `signal_engine`).

**Empfehlung**: Entweder Container umbenennen zu `cdb_signal_engine` ODER Dokumentation durchgehend `cdb_core` verwenden.

---

### ‚úÖ Konflikt 2: ENV-Pr√§fix-Inkonsistenz

**Status**: BEST√ÑTIGT

**Quellen**:
- copilot-instructions.md: Empfehlung "Einheitliches Pr√§fix `CDB_` f√ºr alle projekt-spezifischen Variablen" (DevOps-Anmerkungen, Zeile 39)
- Risikomanagement-Logik.md + extracted_knowledge.md: Alle ENV-Variablen OHNE Pr√§fix (`MAX_POSITION_PCT`, `REDIS_PASSWORD`, etc.)

**Konflikt**: Empfehlung in copilot-instructions.md wird nirgends umgesetzt.

**Auswirkung**: Potenzielle Kollision mit System-ENV oder anderen Tools.

**Empfehlung**: ADR erstellen - entweder Migration zu `CDB_*` mit Breaking Change ODER Empfehlung als "nice-to-have" markieren, aber nicht verpflichtend.

---

### ‚ùå Konflikt 3: Prometheus-Port (FALSIFIZIERT)

**Status**: KEIN KONFLIKT

**Urspr√ºngliche Hypothese**: ARCHITEKTUR.md zeigt 19090, aber docker-compose.yml zeigt 9090.

**Realit√§t**:
- docker-compose.yml Zeile 58: `ports: - "19090:9090"` (Host:Container Mapping)
- ARCHITEKTUR.md: "Prometheus Port 19090 gemappt auf Container-Port 9090 (Standard-Prometheus-Port)"

**Ergebnis**: Korrekt dokumentiert, kein Konflikt. Beide Quellen stimmen √ºberein.

---

### üîç Konflikt 4: Risk-Parameter Defaults (TEILWEISE)

**Status**: MINOR - Dokumentations-L√ºcke

**Quellen**:
- Risikomanagement-Logik.md Zeile 58-61: Defaults angegeben (`MAX_POSITION_PCT` = 0.10, etc.)
- docker-compose.yml, .env: Keine expliziten Defaults sichtbar (Datei nicht committed)

**Konflikt**: Defaults in Doku, aber unklar, ob Code diese Defaults nutzt oder ENV-Variablen zwingend erforderlich sind.

**Validierung ben√∂tigt**: Pr√ºfe `config.py` in Services - laden sie Defaults oder crashen sie bei fehlenden Werten?

**Empfehlung**: Explizit in `extracted_knowledge.md` Abschnitt 5.2 dokumentieren: "Defaults dienen als Referenz, Service crasht bei fehlenden Variablen" (bereits so dokumentiert, OK).

---

## 2. Neu identifizierte Konflikte

### üÜï Konflikt 5: Timeout-Einheiten-Inkonsistenz

**Status**: NEU - Naming-Inkonsistenz

**Quellen**:
- extracted_knowledge.md Abschnitt 5.2: `DATA_STALE_TIMEOUT_SEC` (mit Suffix `_SEC`)
- Andere Timeouts fehlen: Retry-Intervall (60s), Exponential Backoff (max 5 Versuche) - keine ENV-Variablen

**Konflikt**: Nur ein Timeout hat Suffix, andere sind hardcoded.

**Auswirkung**: Inkonsistente Namenskonvention, schwer konfigurierbare Retry-Logik.

**Empfehlung**:
1. Zus√§tzliche ENV-Variablen: `RETRY_INTERVAL_SEC` (Default: 60), `MAX_RETRY_ATTEMPTS` (Default: 5, 10)
2. ODER: Suffix `_SEC` entfernen und Einheit in Doku kl√§ren

---

### üÜï Konflikt 6: Secrets-Validierung vs. Startup-Verhalten

**Status**: NEU - Widerspruch in Fehlerbehandlung

**Quellen**:
- extracted_knowledge.md Abschnitt 5.1: "Fehlerhafte Secrets ‚Üí Retry-Loop mit exponential backoff (max. 5 Versuche, dann Crash)"
- extracted_knowledge.md Abschnitt 5.2: "Fehlende Pflicht-Variablen ‚Üí Container crasht mit Exit Code 1"

**Konflikt**: Fehlende Secrets = sofortiger Crash, ABER fehlerhafte Secrets = Retry-Loop.

**Frage**: Wie unterscheidet der Code zwischen "fehlend" und "fehlerhaft"? Beide sollten konsistent behandelt werden.

**Empfehlung**: Klarstellen - entweder beides Retry ODER beides Crash. Retry macht nur bei Netzwerk-Timeouts Sinn, nicht bei Config-Fehlern.

---

## 3. Redundanzen (eliminierbar)

### Redundanz 1: Port-Listen

**Quellen**:
- ARCHITEKTUR.md Tabelle (Services & Ports)
- docker-compose.yml (Port-Mappings)
- extracted_knowledge.md Abschnitt 1.1 & 1.2 (dupliziert beide Quellen)

**Empfehlung**: In Template NUR auf docker-compose.yml als Single Source of Truth verweisen, nicht in mehreren Dokumenten wiederholen.

---

### Redundanz 2: Event-Schema-Beschreibungen

**Quellen**:
- EVENT_SCHEMA.json (vollst√§ndige Payload-Spezifikation)
- ARCHITEKTUR.md (Event-Topics mit Payload-Elementen)
- extracted_knowledge.md (Event-Topics Tabelle)

**Empfehlung**: In Doku nur Topic-Namen und Quelle (`EVENT_SCHEMA.json`) referenzieren, nicht Payload-Felder wiederholen.

---

### Redundanz 3: Code-Skeleton

**Quellen**:
- SERVICE_TEMPLATE.md (vollst√§ndiges Code-Beispiel)
- extracted_knowledge.md Abschnitt 3.3 (1:1 Kopie)

**Empfehlung**: In Template als separate Datei auslagern (`templates/service_skeleton.py`), nicht inline.

---

## 4. Fehlende Werte (aus Extraktion)

### Fehlend 1: Prometheus Alert-Manager Integration

**Status**: OFFEN in Pipeline 1 & 2

**Quelle**: Audit-Log Pipeline 1 (DevOps-Anmerkungen, Zeile 41)

**L√ºcke**: Keine Dokumentation, ob CRITICAL-Alerts automatisch an Alert-Manager weitergeleitet werden.

**Empfehlung**: Als "TODO" in Template markieren oder explizit als Out-of-Scope dokumentieren.

---

### Fehlend 2: Admin-Befehl f√ºr Drawdown-Freigabe

**Status**: REFERENZ FEHLT

**Quelle**: extracted_knowledge.md Abschnitt 2.4: "manuelle Freigabe via Admin-Befehl erforderlich"

**L√ºcke**: Kein Verweis, wo dieser Befehl dokumentiert ist, wie er aussieht, oder welches Tool ihn ausf√ºhrt.

**Empfehlung**: Entweder Runbook-Referenz hinzuf√ºgen ODER als "TO BE IMPLEMENTED" markieren.

---

### Fehlend 3: Minimum Order Size

**Status**: RISIKO (aus Pipeline 1 Audit)

**Quelle**: Pipeline 1 Audit-Log, Zeile 65

**L√ºcke**: "Order trimmen auf Limit (nicht ablehnen)" - was wenn Signal-Mindestgr√∂√üe unterschritten wird?

**Empfehlung**: ENV-Variable `MIN_ORDER_SIZE` einf√ºhren ODER explizit dokumentieren, dass Trimming keine Mindestgr√∂√üe pr√ºft.

---

## Zusammenfassung

**Validierte Konflikte**: 2 (Service-Namen, ENV-Pr√§fix)
**Neu identifiziert**: 2 (Timeout-Einheiten, Secrets-Verhalten)
**Redundanzen**: 3 (Ports, Event-Schema, Code-Skeleton)
**Fehlende Werte**: 3 (Alert-Manager, Admin-Befehl, Min Order Size)

**N√§chster Schritt**: software-jochen konsolidiert `extracted_knowledge.md` basierend auf diesen Findings.
