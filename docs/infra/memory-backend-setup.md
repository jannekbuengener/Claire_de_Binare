# Memory Backend Setup Guide

**Persistent memory for Auto-Claude agents using Graphiti MCP + Ollama**

## Overview

The Memory Backend provides cross-session persistent memory for Auto-Claude agents using a knowledge graph architecture. Memories are stored in FalkorDB and searchable via semantic embeddings generated by Ollama.

### Key Benefits

✅ **Persistent Memory** - Agent memories survive container restarts and sessions
✅ **Semantic Search** - Find relevant memories using natural language queries
✅ **Local Processing** - All embeddings generated locally via Ollama (no external API calls)
✅ **MCP Protocol** - Standard Model Context Protocol for agent read/write operations
✅ **Knowledge Graph** - Entities and relationships stored in FalkorDB graph database

---

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    Auto-Claude Agent                         │
└─────────────────────┬───────────────────────────────────────┘
                      │ MCP Protocol (HTTP)
                      ▼
┌─────────────────────────────────────────────────────────────┐
│         Graphiti + FalkorDB Combined Container               │
│         zepai/graphiti-falkordb:latest                       │
│  ┌─────────────────────────────────────────────────────────┐│
│  │    ┌─────────────────┐  ┌────────────────────────────┐  ││
│  │    │ Graphiti MCP    │  │   Embedded FalkorDB        │  ││
│  │    │ Server (:8000)  │  │   (Internal :6379)         │  ││
│  │    │ Endpoint: /mcp/ │  │   Graph Data Storage       │  ││
│  │    └────────┬────────┘  └────────────────────────────┘  ││
│  │             │ Internal Redis Protocol                    ││
│  │    Browser UI (optional): :3000                          ││
│  └─────────────────────────────────────────────────────────┘│
│  Volume: cdb_graphiti_data:/var/lib/falkordb/data           │
└───────────────────────────────────────────────────────────┬─┘
                      │ OpenAI-compatible API
                      ▼
            ┌─────────────────────┐
            │   Ollama (:11434)   │
            │  ┌───────────────┐  │
            │  │nomic-embed-txt│  │
            │  │deepseek-r1:7b │  │
            │  └───────────────┘  │
            │  Volume: ollama_data│
            └─────────────────────┘
```

---

## Prerequisites

Before starting the memory stack:

```powershell
# Verify you're in project root
Test-Path infrastructure/compose/memory.yml  # Must return True

# Verify .env.memory exists (copy from .env.memory.example if missing)
Test-Path .env.memory  # Must return True

# Verify Docker is running
docker info  # Must succeed (no errors)

# Verify disk space (models require ~10GB)
# Windows:
Get-PSDrive C | Select-Object Free
# Linux/Mac:
df -h /
```

### System Requirements

| Requirement | Minimum | Recommended |
|-------------|---------|-------------|
| Disk Space | 10 GB | 20 GB |
| RAM | 8 GB | 16 GB |
| Docker | v20.10+ | v24.0+ |
| Docker Compose | v2.0+ | v2.20+ |

---

## Quick Start

### 1. Create Environment File

```powershell
# Copy template
Copy-Item .env.memory.example .env.memory

# Or on Linux/Mac:
cp .env.memory.example .env.memory
```

### 2. Start Memory Stack

**Windows (PowerShell):**
```powershell
.\infrastructure\scripts\init-memory.ps1
```

**Linux/Mac (Bash):**
```bash
chmod +x infrastructure/scripts/init-memory.sh
./infrastructure/scripts/init-memory.sh
```

**Expected output:**
```
=== Memory Backend Initialization ===

[1/4] Starting memory stack containers...
[+] Running 3/3
 ✔ Network ${STACK_NAME:-cdb}-memory_cdb_memory_network  Created
 ✔ Container cdb_ollama        Started
 ✔ Container cdb_graphiti      Started

[2/4] Waiting for Ollama API...
✓ Ollama API ready at http://localhost:11434

[3/4] Pulling required models...
  Pulling nomic-embed-text...
  ✓ nomic-embed-text ready
  Pulling deepseek-r1:7b...
  ✓ deepseek-r1:7b ready

[4/4] Waiting for Graphiti MCP Server...
✓ Graphiti MCP ready at http://localhost:8000

=== Initialization Complete ===
MCP Endpoint: http://localhost:8000/mcp/
```

### 3. Verify Setup

```powershell
# Check container health
docker ps --filter name=cdb_graphiti --filter name=cdb_ollama --format "table {{.Names}}\t{{.Status}}"

# Expected:
# NAMES          STATUS
# cdb_graphiti   Up 2 minutes (healthy)
# cdb_ollama     Up 2 minutes (healthy)

# Test Ollama API
curl http://localhost:11434/api/tags

# Test Graphiti health
curl http://localhost:8000/health
```

---

## Service URLs and Ports

| Service | URL | Purpose |
|---------|-----|---------|
| Graphiti MCP | `http://localhost:8000/mcp/` | MCP protocol endpoint for agent memory operations |
| Graphiti Health | `http://localhost:8000/health` | Health check endpoint |
| Ollama API | `http://localhost:11434/v1` | OpenAI-compatible embedding/LLM API |
| Ollama Tags | `http://localhost:11434/api/tags` | List available models |
| FalkorDB Browser | `http://localhost:3000` | Graph database UI (optional, disabled by default) |

---

## Environment Variables

### Required Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `OPENAI_API_KEY` | `ollama` | Placeholder for Ollama (must be non-empty) |
| `OPENAI_API_BASE` | `http://cdb_ollama:11434/v1` | Ollama API endpoint (inter-container) |
| `OPENAI_MODEL` | `deepseek-r1:7b` | LLM model for knowledge extraction |
| `DATABASE_PROVIDER` | `falkordb` | Database backend (always falkordb) |
| `GRAPHITI_GROUP_ID` | `auto-claude` | Memory namespace for agent memories |

### Optional Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `SEMAPHORE_LIMIT` | `10` | Concurrent episode processing limit |
| `GRAPHITI_TELEMETRY_ENABLED` | `false` | Anonymous telemetry (disabled for privacy) |
| `BROWSER` | `0` | FalkorDB Browser UI (set `1` to enable) |
| `FALKORDB_URI` | `redis://localhost:6379` | FalkorDB connection (internal to container) |

---

## Auto-Claude Integration

### Configure MCP Client

Add the memory server to your MCP client configuration:

**Option 1: Update `.mcp.json` (project-level)**
```json
{
  "mcpServers": {
    "graphiti-memory": {
      "transport": "http",
      "url": "http://localhost:8000/mcp/"
    }
  }
}
```

**Option 2: Update Claude settings (global)**
Add the same configuration to your Claude Code settings file.

### Available MCP Methods

| Method | Description |
|--------|-------------|
| `add_episode` | Write a new memory episode to the knowledge graph |
| `search` | Search memories using semantic or hybrid search |
| `get_entity` | Retrieve a specific entity by ID |
| `delete_episode` | Remove an episode from the knowledge graph |

### Example Usage

```python
# Writing a memory
mcp_call("add_episode", {
    "content": "User prefers TypeScript over JavaScript",
    "source": "conversation",
    "group_id": "auto-claude"
})

# Searching memories
mcp_call("search", {
    "query": "user programming preferences",
    "limit": 5
})
```

---

## Stack Operations

### Start Stack

```powershell
docker compose -f infrastructure/compose/memory.yml up -d
```

### Stop Stack (Preserves Data)

```powershell
docker compose -f infrastructure/compose/memory.yml down
```

**Data safety:**
- ✅ FalkorDB data preserved (volume: `cdb_graphiti_data`)
- ✅ Ollama models preserved (volume: `cdb_ollama_data`)

### Health Check

```powershell
# Quick status
docker compose -f infrastructure/compose/memory.yml ps

# Detailed health
docker ps --filter name=cdb_graphiti --filter name=cdb_ollama --format "{{.Names}}: {{.Status}}"

# Expected (healthy):
# cdb_graphiti: Up 5 minutes (healthy)
# cdb_ollama: Up 5 minutes (healthy)
```

### View Logs

```powershell
# All memory services
docker compose -f infrastructure/compose/memory.yml logs -f

# Specific service
docker logs cdb_graphiti --tail 50
docker logs cdb_ollama --tail 50
```

### Reset Stack (Nuclear Option)

**⚠️ WARNING: This DELETES ALL MEMORY DATA**

```powershell
# Stop and remove volumes
docker compose -f infrastructure/compose/memory.yml down -v

# Restart fresh
docker compose -f infrastructure/compose/memory.yml up -d

# Re-pull models
docker compose -f infrastructure/compose/memory.yml exec cdb_ollama ollama pull nomic-embed-text
docker compose -f infrastructure/compose/memory.yml exec cdb_ollama ollama pull deepseek-r1:7b
```

---

## Verification Steps

### 1. Container Health

```powershell
# All containers should show "(healthy)"
docker ps --filter name=cdb_graphiti --filter name=cdb_ollama
```

### 2. Ollama Models Loaded

```powershell
# List available models
docker exec cdb_ollama ollama list

# Expected output:
# NAME                    SIZE
# nomic-embed-text        274 MB
# deepseek-r1:7b          4.7 GB
```

### 3. MCP Endpoint Responsive

```powershell
# Health check
curl http://localhost:8000/health

# Expected: 200 OK or {"status": "healthy"}
```

### 4. FalkorDB Connection (Internal)

```powershell
# Ping FalkorDB (via combined container)
docker exec cdb_graphiti redis-cli -p 6379 PING

# Expected: PONG
```

### 5. Volume Persistence

```powershell
# Verify volumes exist
docker volume ls --filter name=cdb_graphiti_data
docker volume ls --filter name=cdb_ollama_data
```

---

## Troubleshooting

### Issue: "Container cdb_ollama unhealthy"

**Cause:** Ollama still loading models or out of memory.

**Solution:**
```powershell
# Check logs for errors
docker logs cdb_ollama --tail 100

# If OOM, increase Docker memory limit
# Docker Desktop → Settings → Resources → Memory → 8GB+

# Restart Ollama
docker compose -f infrastructure/compose/memory.yml restart cdb_ollama
```

### Issue: "Container cdb_graphiti unhealthy"

**Cause:** Cannot connect to Ollama or FalkorDB initialization failed.

**Solution:**
```powershell
# Check logs
docker logs cdb_graphiti --tail 100

# Verify Ollama is healthy first
curl http://localhost:11434/api/tags

# Restart Graphiti
docker compose -f infrastructure/compose/memory.yml restart cdb_graphiti
```

### Issue: "Connection refused on port 8000"

**Cause:** Graphiti container not running or port conflict.

**Solution:**
```powershell
# Check if container is running
docker ps --filter name=cdb_graphiti

# Check for port conflicts
netstat -ano | findstr :8000

# If conflict, stop conflicting process or change port in memory.yml
```

### Issue: "Model not found: nomic-embed-text"

**Cause:** Models not pulled during initialization.

**Solution:**
```powershell
# Manually pull models
docker compose -f infrastructure/compose/memory.yml exec cdb_ollama ollama pull nomic-embed-text
docker compose -f infrastructure/compose/memory.yml exec cdb_ollama ollama pull deepseek-r1:7b

# Verify
docker exec cdb_ollama ollama list
```

### Issue: "OPENAI_API_KEY not set"

**Cause:** Empty API key (Ollama requires non-empty placeholder).

**Solution:**
```powershell
# Check .env.memory file
cat .env.memory | grep OPENAI_API_KEY

# Must be: OPENAI_API_KEY=ollama (not empty!)
```

### Issue: "First request very slow"

**Cause:** Cold start - models loading into memory.

**Solution:**
- This is normal on first use
- Subsequent requests will be faster
- Consider warming up models after container start

---

## Troubleshooting Matrix

| Symptom | Likely Cause | Fix |
|---------|--------------|-----|
| Compose fails to start | YAML syntax error | Run `docker compose -f infrastructure/compose/memory.yml config` |
| Container exits immediately | Missing ENV variable | Check `.env.memory` complete |
| cdb_graphiti unhealthy | Ollama not ready | Wait for Ollama health, then restart Graphiti |
| Port conflict error | Another process using port | Check `netstat -ano \| findstr <port>` |
| Models not found | Init script not run | Run `init-memory.ps1` or `init-memory.sh` |
| Slow first request | Cold model loading | Normal - wait for warmup |
| Memory not persisting | Volumes deleted | Check `docker volume ls` for cdb_* volumes |

---

## File Reference

| File | Purpose |
|------|---------|
| `infrastructure/compose/memory.yml` | Docker Compose orchestration |
| `.env.memory.example` | Environment template |
| `.env.memory` | Active environment (create from template) |
| `infrastructure/config/graphiti/graphiti_config.yaml` | Graphiti server config (optional) |
| `infrastructure/config/mcp/mcp-clients.json` | MCP client configuration reference |
| `infrastructure/scripts/init-memory.sh` | Bash initialization script |
| `infrastructure/scripts/init-memory.ps1` | PowerShell initialization script |

---

## Related Documentation

- [Stack Lifecycle](../STACK_LIFECYCLE.md) - Docker stack operations
- [Compose Architecture](../architecture/COMPOSE_ARCHITECTURE.md) - Compose file patterns
- [Security Hardening](../SECURITY_HARDENING.md) - Security best practices

---

**Last Updated:** 2025-12-29
**Status:** ✅ Ready for Use
