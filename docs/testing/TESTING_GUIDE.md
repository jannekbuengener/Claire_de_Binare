# Testing Guide â€“ Claire de Binaire

Umfassende Anleitung fÃ¼r das Testing-Framework von Claire de Binaire.

---

## ðŸ“‹ Inhaltsverzeichnis

1. [Ãœbersicht](#Ã¼bersicht)
2. [Quick Start](#quick-start)
3. [Test-Typen](#test-typen)
4. [Test-AusfÃ¼hrung](#test-ausfÃ¼hrung)
5. [Coverage](#coverage)
6. [Pre-Commit Hooks](#pre-commit-hooks)
7. [CI/CD Integration](#cicd-integration)
8. [Best Practices](#best-practices)

---

## Ãœbersicht

### Test-Statistiken

```
Total Tests:     73 passed, 1 skipped
Coverage:        100% (53/53 statements)
Test Files:      6 aktive Dateien
Test Types:      Unit (65), Integration (5), Property-Based (8)
Runtime:         ~2.5 seconds (all tests)
```

### Test-Framework

- **pytest** â€“ Test Runner & Framework
- **pytest-cov** â€“ Coverage Reporting
- **pytest-mock** â€“ Mocking fÃ¼r Integration Tests
- **hypothesis** â€“ Property-Based Testing
- **pyyaml** â€“ Docker Compose Validation

---

## Quick Start

### 1. Installation

```bash
# Dependencies installieren
pip install -r requirements-dev.txt

# Optional: Pre-Commit Hooks aktivieren
./scripts/setup-dev.sh
```

### 2. Tests ausfÃ¼hren

```bash
# Alle Tests
pytest -v

# Mit Coverage
pytest --cov=services --cov-report=html

# Nur schnelle Unit-Tests
pytest -v -m unit
```

### 3. Coverage Report anschauen

```bash
# HTML Report generieren
pytest --cov=services --cov-report=html

# Browser Ã¶ffnen
open htmlcov/index.html  # macOS
xdg-open htmlcov/index.html  # Linux
```

---

## Test-Typen

### 1. Unit Tests (65 Tests)

**Zweck**: Isolierte Tests einzelner Funktionen ohne externe Dependencies.

**Marker**: `@pytest.mark.unit`

**Beispiele**:
- `test_risk_engine_core.py` â€“ Basis-FunktionalitÃ¤t
- `test_risk_engine_edge_cases.py` â€“ Edge-Cases & Grenzwerte
- `test_docker_compose_validation.py` â€“ Config-Validierung

**AusfÃ¼hrung**:
```bash
pytest -v -m unit
```

**Eigenschaften**:
- âœ… Schnell (<0.1s pro Test)
- âœ… Keine externen Services (Redis/PostgreSQL)
- âœ… Deterministisch
- âœ… FÃ¼r CI/CD geeignet

---

### 2. Parametrized Tests (39 Test-Szenarien)

**Zweck**: Mehrere Szenarien mit einem Test abdecken.

**Datei**: `test_risk_engine_parametrized.py`

**Beispiel**:
```python
@pytest.mark.unit
@pytest.mark.parametrize(
    "daily_pnl,expected_approved",
    [
        (-6000.0, False),  # Ãœber Limit
        (-5000.0, False),  # Am Limit
        (-4999.9, True),   # Unter Limit
    ],
)
def test_daily_drawdown_scenarios(daily_pnl, expected_approved):
    # Test mit verschiedenen PnL-Werten
    ...
```

**Kategorien**:
- Daily Drawdown (7 Szenarien)
- Exposure Limits (7 Szenarien)
- Position Sizing (10 Szenarien)
- Stop-Loss (10 Szenarien)
- Boundary Values (5 Szenarien)

---

### 3. Property-Based Tests (8 Tests)

**Zweck**: Automatisches Finden von Edge-Cases durch randomisierte Inputs.

**Framework**: Hypothesis

**Datei**: `test_risk_engine_hypothesis.py`

**Beispiel**:
```python
from hypothesis import given, strategies as st

@pytest.mark.unit
@given(
    equity=st.floats(min_value=1000.0, max_value=10_000_000.0),
    price=st.floats(min_value=0.01, max_value=1_000_000.0),
)
def test_position_size_never_exceeds_max_pct(equity, price):
    # Hypothesis generiert automatisch 100+ Test-FÃ¤lle
    ...
```

**Getestete Invarianten**:
- Position-Size Ã¼berschreitet nie MAX_POSITION_PCT
- Stop-Loss immer korrekt platziert (Long/Short)
- Drawdown-Decisions konsistent
- Exposure-Limits respektiert

**AusfÃ¼hrung**:
```bash
# Mit Statistics
pytest tests/test_risk_engine_hypothesis.py --hypothesis-show-statistics

# Mehr Test-FÃ¤lle generieren
pytest tests/test_risk_engine_hypothesis.py --hypothesis-max-examples=1000
```

---

### 4. Integration Tests (5 Tests)

**Zweck**: Testen der Interaktion zwischen Services (mit Mocks).

**Marker**: `@pytest.mark.integration`

**Datei**: `test_event_pipeline.py`

**Beispiel**:
```python
@pytest.mark.integration
def test_end_to_end_signal_to_order_flow(mock_redis, ...):
    # Simuliert: Signal â†’ Risk â†’ Order Pipeline
    ...
```

**Test-Szenarien**:
- Redis Pub/Sub Event-Flow
- PostgreSQL Persistence
- End-to-End Signalâ†’Order Pipeline
- Rejected Signal Handling
- Batch Signal Processing

**AusfÃ¼hrung**:
```bash
pytest -v -m integration
```

---

### 5. Docker Compose Validation (9 Tests)

**Zweck**: Validierung der docker-compose.yml ohne Docker.

**Datei**: `test_docker_compose_validation.py`

**Getestet**:
- âœ… YAML-Syntax gÃ¼ltig
- âœ… Required Services vorhanden
- âœ… Health-Checks konfiguriert
- âœ… Ports korrekt gemappt
- âœ… Volumes konfiguriert
- âœ… Networks korrekt
- âœ… Restart-Policies gesetzt

---

## Test-AusfÃ¼hrung

### Basis-Kommandos

```bash
# Alle Tests
pytest -v

# Nur Unit-Tests (schnell)
pytest -v -m unit

# Nur Integration-Tests
pytest -v -m integration

# Spezifische Datei
pytest -v tests/test_risk_engine_core.py

# Spezifischer Test
pytest -v tests/test_risk_engine_core.py::test_daily_drawdown_blocks_orders
```

### Mit Coverage

```bash
# Terminal-Report
pytest --cov=services --cov-report=term-missing

# HTML-Report
pytest --cov=services --cov-report=html
open htmlcov/index.html

# JSON-Report (fÃ¼r CI/CD)
pytest --cov=services --cov-report=json

# Coverage-Threshold erzwingen
pytest --cov=services --cov-fail-under=95
```

### Fortgeschritten

```bash
# Parallele AusfÃ¼hrung (mit pytest-xdist)
pytest -n auto

# Nur fehlgeschlagene Tests erneut
pytest --lf

# Stop bei erstem Fehler
pytest -x

# Verbose Output mit Tracebacks
pytest -vv -s

# Mit pdb bei Fehler
pytest --pdb

# Hypothese mit mehr Beispielen
pytest tests/test_risk_engine_hypothesis.py --hypothesis-max-examples=500
```

---

## Coverage

### Coverage-Report verstehen

```
Name                      Stmts   Miss  Cover   Missing
-------------------------------------------------------
services/__init__.py          0      0   100%
services/risk_engine.py      53      0   100%
-------------------------------------------------------
TOTAL                        53      0   100%
```

**Spalten**:
- **Stmts**: Anzahl ausfÃ¼hrbarer Statements
- **Miss**: Nicht abgedeckte Statements
- **Cover**: Coverage-Prozentsatz
- **Missing**: Zeilen ohne Coverage

### Coverage-Ziele

```
âœ… Minimum: 95% (CI/CD Threshold)
âœ… Target:  100%
âœ… Aktuell: 100% âœ¨
```

### HTML-Report

Der HTML-Report zeigt:
- âœ… Line-by-Line Coverage
- âš ï¸ Ungetestete Branches
- ðŸ“Š Function-Level Coverage
- ðŸ” Fehlende Lines highlighted

```bash
pytest --cov=services --cov-report=html
open htmlcov/index.html
```

---

## Pre-Commit Hooks

### Aktivierung

```bash
# Automatisch via Script
./scripts/setup-dev.sh

# Manuell
cp scripts/hooks/pre-commit .git/hooks/pre-commit
chmod +x .git/hooks/pre-commit
```

### Was wird geprÃ¼ft?

Vor jedem Commit:

1. âœ… **Unit Tests** laufen durch
2. âœ… **Coverage** â‰¥ 95%
3. âœ… **Keine Debug-Statements** (`pdb`, `breakpoint()`, `print()`)
4. âš ï¸ **TODO/FIXME** werden gewarnt (kein Fail)

### Hook deaktivieren (temporÃ¤r)

```bash
# FÃ¼r einen Commit Ã¼berspringen
git commit --no-verify -m "message"
```

---

## CI/CD Integration

### GitHub Actions

**Workflow**: `.github/workflows/pytest.yml`

**Trigger**:
- Push zu `main`, `develop`, `claude/**`
- Pull Requests zu `main`, `develop`

**Matrix**:
- Python 3.11
- Python 3.12

**Steps**:
1. Checkout Code
2. Setup Python + Cache
3. Install Dependencies
4. Run pytest + Coverage
5. Upload Coverage zu Codecov
6. Enforce 95% Threshold

### Docker Health Check

**Workflow**: `.github/workflows/docker-health.yml`

**PrÃ¼ft**:
- âœ… docker-compose.yml Syntax
- âœ… PostgreSQL Health
- âœ… Redis Health
- âœ… Container Startup

---

## Best Practices

### 1. Test-Struktur (Arrange-Act-Assert)

```python
@pytest.mark.unit
def test_position_size_respects_max_pct():
    # Arrange - Setup
    signal = {"price": 50_000.0, "size": 1.0}
    config = {"MAX_POSITION_PCT": 0.10, "ACCOUNT_EQUITY": 100_000.0}

    # Act - AusfÃ¼hrung
    size = risk_engine.limit_position_size(signal, config)

    # Assert - PrÃ¼fung
    assert size == pytest.approx(0.2)
```

### 2. Fixtures nutzen

```python
# Aus conftest.py wiederverwendbar
def test_with_fixtures(risk_config, sample_signal_event):
    # Fixtures automatisch injiziert
    decision = risk_engine.evaluate_signal(sample_signal_event, ...)
    ...
```

### 3. Sprechende Test-Namen

```python
# âœ… GUT
def test_daily_drawdown_blocks_orders_when_limit_exceeded():
    ...

# âŒ SCHLECHT
def test_dd():
    ...
```

### 4. Docstrings mit Kontext

```python
def test_exposure_limit_exceeded():
    """Signal wird blockiert wenn total_exposure_pct > MAX_EXPOSURE_PCT.

    Gegeben: Portfolio mit 28% Exposure
    Wenn: Signal wÃ¼rde 10% hinzufÃ¼gen (â†’ 38% > 30% limit)
    Dann: Signal wird mit Grund 'max_exposure_reached' abgelehnt
    """
    ...
```

### 5. Parametrize fÃ¼r Ã¤hnliche Tests

```python
# Statt 5 separate Tests
@pytest.mark.parametrize("pnl,expected", [
    (-6000, False),
    (-5000, False),
    (0, True),
])
def test_drawdown_scenarios(pnl, expected):
    ...
```

### 6. Hypothesis fÃ¼r komplexe Invarianten

```python
# Automatisch 100+ randomisierte Test-FÃ¤lle
@given(equity=st.floats(min_value=1000.0, max_value=1_000_000.0))
def test_position_size_invariant(equity):
    ...
```

---

## Troubleshooting

### Tests finden nicht

```bash
# Cache lÃ¶schen
pytest --cache-clear
rm -rf .pytest_cache

# Expliziter Pfad
pytest -v tests/
```

### Import-Errors

```bash
# PYTHONPATH setzen
export PYTHONPATH=$PYTHONPATH:$(pwd)

# Oder pytest mit -s
pytest -v -s
```

### Hypothesis Fehler

```bash
# Seed fÃ¼r Reproduzierbarkeit
pytest tests/test_risk_engine_hypothesis.py --hypothesis-seed=12345

# Database lÃ¶schen
rm -rf .hypothesis/
```

### Coverage zu niedrig

```bash
# Fehlende Lines anzeigen
pytest --cov=services --cov-report=term-missing

# HTML fÃ¼r Details
pytest --cov=services --cov-report=html
```

---

## Weitere Ressourcen

- [pytest Dokumentation](https://docs.pytest.org/)
- [pytest-cov Guide](https://pytest-cov.readthedocs.io/)
- [Hypothesis Dokumentation](https://hypothesis.readthedocs.io/)
- [conftest.py](../../tests/conftest.py) â€“ Projekt-spezifische Fixtures

---

**Version**: 1.0
**Letzte Aktualisierung**: 2025-11-19
**Maintainer**: Claire de Binaire Team
