---
status: archived
migration_status: resolved
## note: "Legacy file-links entfernt, Textreferenzen beibehalten (ADR-027)"

## cdb\_redis

F√ºr einen Neuaufbau des **Claire de Binaire** Servers wird zun√§chst eine geeignete Systemumgebung ben√∂tigt. Idealerweise steht ein **aktueller x64-Server oder Rechner** zur Verf√ºgung (getestet wurde z.‚ÄØB. auf Docker Desktop unter Windows) mit installiertem **Docker** und **Docker-Compose**[\[1\]]. Dadurch sind Anforderungen an das Basis-Betriebssystem gering ‚Äì Linux oder Windows mit Docker-Unterst√ºtzung reichen aus. F√ºr den Betrieb sollten ca. 1‚Äì2‚ÄØGB RAM und eine stabile Internetverbindung eingeplant werden, da Marktdaten in Echtzeit von der **MEXC**\-API bezogen werden.

**Software/Services:** Ben√∂tigt werden Container-Images f√ºr **Redis** (Message-Bus) und **PostgreSQL** (Datenbank), sowie die Python-basierten Microservices des Bots selbst (als Docker-Images). Docker-Compose orchestriert diese Komponenten. Beim Neuaufsetzen zieht Docker-Compose die Basis-Images (z.‚ÄØB. redis:7-alpine und postgres:15-alpine) automatisch aus dem Registry[\[2\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L28-L36)[\[3\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L9-L17).

**Zugriffstokens & Secrets:** In einer konfigurierten **.env**\-Datei sind alle sensiblen Zugangsdaten und Konfigurationswerte abzulegen. Dazu z√§hlen insbesondere:

* **MEXC API Key & Secret:** API-Schl√ºssel f√ºr die B√∂rse (nur Lese-/Handelsrechte, **keine Withdraw-Rechte** gem√§√ü Sicherheitsrichtlinie[\[4\]]). Diese sind in den Env-Vars MEXC\_API\_KEY und MEXC\_API\_SECRET zu hinterlegen[\[5\]]. Ebenso die Basis-URL der API (MEXC\_BASE, default: MEXC Contract-API).

* **Redis-Zugang:** Ein Redis-Instanz wird als Message-Bus genutzt. In der .env m√ºssen REDIS\_PASSWORD (gem√§√ü Compose erforderlich[\[6\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L13-L19)) und ggf. Host/Port stehen. Standardm√§√üig verbinden die Services auf REDIS\_HOST=redis (Container-Hostname) und Port 6379[\[7\]].

* **PostgreSQL-Zugang:** Die Datenbank-Zugangsdaten POSTGRES\_USER, POSTGRES\_PASSWORD und der Datenbankname POSTGRES\_DB sind anzugeben[\[8\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L32-L40). Im Docker-Setup wird z.‚ÄØB. ein User *cdb\_user* und die DB *claire\_de\_binare* genutzt (siehe unten).

* **Weitere Secrets:** F√ºr Benachrichtigungen via Web-Push sind ‚Äì falls das Notification-Service genutzt wird ‚Äì ein VAPID-Schl√ºsselpaar (WEBPUSH\_VAPID\_PUBLIC\_KEY, WEBPUSH\_VAPID\_PRIVATE\_KEY) sowie ein Kontakt-URL (WEBPUSH\_CONTACT) erforderlich[\[9\]]. Legacy-Optionen wie Telegram-Bot-Token und Chat-ID k√∂nnen entfallen[\[10\]].

**Hardware**: Spezielle Hardware ist nicht erforderlich, da alle Komponenten in Docker-Containern laufen. Eine zuverl√§ssige **Speicherl√∂sung** f√ºr Persistenz sollte vorhanden sein (Docker Volumes f√ºr Datenbank und ggf. Logs), sowie genug CPU-Ressourcen f√ºr die Datenverarbeitung in Echtzeit. Backups (siehe unten **Sicherheit & Recovery**) sollten auf ein separates Medium/Verzeichnis erfolgen.

## 2\. Deployment Stack (Docker, Compose, Python, Redis, PostgreSQL, Flask)

Claire de Binaire setzt auf einen **containerisierten Deployment-Stack** zur einheitlichen Bereitstellung aller Komponenten. Kernbestandteile und ihr Zusammenspiel:

* **Docker & Docker-Compose:** Alle Services laufen in Docker-Containern, definiert durch individuelle Dockerfile\-Rezepte und orchestriert √ºber eine zentrale docker-compose.yml. Docker-Compose startet die Infrastruktur (Redis, Postgres, Monitoring) sowie die Bot-Services in korrekter Reihenfolge. Beispielsweise wird in der Compose-Datei der Redis-Container cdb\_redis definiert (mit persistentem Volume f√ºr Daten und Passwortschutz)[\[3\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L9-L17), ebenso der PostgreSQL-Container cdb\_postgres mit Initialisierung des DB-Schemas[\[8\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L32-L40). Die Compose-Datei legt zudem fest, welche Ports nach au√üen ge√∂ffnet werden, und nutzt depends\_on, um Abh√§ngigkeiten und Startreihenfolge auszudr√ºcken (z.‚ÄØB. muss Redis laufen, bevor die Signal-Engine startet[\[11\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L178-L186)).

* **Python-Anwendungen & Requirements:** Die fachliche Logik ist in **Python** implementiert (Version 3.11). Jedes Microservice-Modul hat sein eigenes Verzeichnis mit Code und eine requirements.txt f√ºr Dependencies. Wichtige Bibliotheken sind u.‚ÄØa. **Flask** (f√ºr HTTP-Endpunkte wie Health-Checks), **redis-py** (f√ºr die Pub/Sub-Anbindung), ggf. **ccxt** (f√ºr B√∂rsen-API-Zugriff in der Execution) sowie ORMs/DB-Treiber wie SQLAlchemy und Psycopg2 f√ºr die Datenbankanbindung[\[12\]]. Die requirements.txt der Services listen nur dienstspezifische Abh√§ngigkeiten (z.‚ÄØB. Flask, redis, dotenv) ‚Äì dadurch bleiben die Container schlank[\[13\]][\[14\]].

* **Flask Microservices:** Jeder Service ist als eigenst√§ndige Flask-Anwendung gestaltet. Flask stellt minimale HTTP-Endpunkte bereit ‚Äì vor allem /health f√ºr Health-Checks, evtl. /status oder /metrics f√ºr Statusabfragen[\[15\]]. Die Flask-App l√§uft innerhalb des Containers auf dem vorgesehenen Port (siehe unten Architektur/Ports) und erm√∂glicht so Docker-Compose Healthchecks. Im Dockerfile wird daf√ºr der Port exponiert und ein Healthcheck-CMD definiert (z.‚ÄØB. via curl auf /health)[\[16\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L14-L19)[\[17\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L20-L23). Die Flask-Server starten in den jeweiligen service.py\-Mainprogrammen.

* **Redis (Message-Bus):** Redis dient als zentrales **Pub/Sub-Message-Bus** f√ºr die lose gekoppelte Kommunikation zwischen den Microservices. Der Redis-Container wird mit Persistenz (AppendOnly Log) konfiguriert und im Compose-File hinterlegt[\[18\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L16-L24). Alle Services verbinden sich √ºber die in .env konfigurierten Host/Port/Passwort auf diesen Bus. Ereignisse wie Marktdaten, Signale etc. werden als JSON-Nachrichten √ºber definierte Channels (Topics) ver√∂ffentlicht ‚Äì Redis verteilt sie an alle abonnierten Dienste (siehe Architekturbeschreibung).

* **PostgreSQL (Persistenz):** Die relationale Datenbank speichert **persistente Daten**: Signale, Trades, Risk-Entscheidungen, Performance-Metriken usw. Beim Initialstart legt der Postgres-Container mittels eingebundenem Schema-SQL-Skript die n√∂tigen Tabellen an[\[19\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L38-L44). Der DB-Zugriff erfolgt aus den Services heraus (z.‚ÄØB. Speichern von Trades nach Ausf√ºhrung). Wichtig: Vor dem Start m√ºssen die DB-Zugangsdaten in .env stimmen, da die Services diese nutzen, um eine DB-Verbindung aufzubauen. Im Compose ist Postgres durch depends\_on bei der Execution-Komponente ber√ºcksichtigt (Execution-Service wartet auf DB-Start)[\[20\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L236-L244).

**Docker-Aufbau (Dockerfiles):** Jedes Microservice-Modul hat ein eigenes Dockerfile, meist basierend auf python:3.11-slim. Darin werden die Abh√§ngigkeiten installiert und der Anwendungscode kopiert[\[21\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L9-L16). Es wird ein eingeschr√§nkter **Non-Root-User** erstellt (Security Best Practice: ‚Äûleast privilege‚Äú)[\[22\]][\[16\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L14-L19), und der Standard-Startbefehl f√ºhrt die Python-Service-Main aus. Beispielhaft zeigt der Dockerfile-Auszug des Risk-Manager-Dienstes die Erstellung eines Users und einen Healthcheck-Befehl:

RUN useradd \-m \-u 1000 riskuser && chown \-R riskuser:riskuser /app
USER riskuser
HEALTHCHECK \--interval=30s \--timeout=3s \--retries=3 \\
    CMD curl \-f http://localhost:8002/health || exit 1
EXPOSE 8002
CMD \["python", "-u", "service.py"\]

*Quelle: Risk-Manager Dockerfile[\[23\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L14-L22).*

**docker-compose.yml:** In der Compose-Datei sind alle Container und deren Konfiguration vermerkt. Zentral ist das **Zusammenspiel der Services**: z.‚ÄØB. startet der bot\_ws (WebSocket-Datenfeed) Container erst nach Redis[\[24\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L112-L119); die signal\_engine (Signal-Engine) startet nach Redis *und* dem Datenfeed[\[11\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L178-L186); der risk\_manager wartet auf Redis und die Signal-Engine[\[25\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L206-L214); die execution\_service h√§ngt von Redis, Risk-Manager *und* Datenbank ab[\[20\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L236-L244). Diese Staffelung stellt sicher, dass bei einem Neustart jeder Dienst seine ben√∂tigten Gegenstellen vorfindet. Compose verwaltet auch gemeinsame **Netzwerke** (hier ein Bridge-Netz cdb\_network f√ºr internen Traffic[\[26\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L24-L27)[\[27\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L252-L255)) und **Volumes** (f√ºr persistente Redis-/Postgres-Daten[\[28\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L16-L19)[\[29\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L36-L40)). Die Ports der Services werden meist 1:1 an den Host gemappt (8000/8001/8002/etc.), w√§hrend interne Verbindungen √ºber den Service-Namen laufen (z.‚ÄØB. redis:6379).

## 3\. Architektur√ºberblick (Microservices & Event-Bus)

Claire de Binaire folgt einer **Microservice-Architektur** mit entkoppelten, ereignisgesteuerten Komponenten[\[30\]]. Gem√§√ü *ARCHITEKTUR.md* sind folgende Haupt-Services definiert:

* **Datenfeed / Ingestion-Service:** Bezieht in Echtzeit Marktdaten von MEXC (WebSocket-Streams f√ºr Kurse/Orderbuch, REST f√ºr periodische Updates), normalisiert die Daten und publiziert sie als **MarketData-Events** auf dem Message-Bus[\[31\]]. (Im aktuellen Setup entspricht dies dem bot\_ws Container, der z.‚ÄØB. Top-5 M√§rkte streamt.)

* **Strategie-Engine (Signal-Generator):** Subskribiert die Marktdaten und berechnet kontinuierlich definierte **Indikatoren** (Momentum, Volumen-Spikes, Orderbuch-Imbalance etc.). Sobald die Regeln ein Handelssignal ausl√∂sen (Kauf/Verkauf inkl. Begr√ºndung), wird ein **Signal-Event** auf dem Bus publiziert[\[32\]]. (Beispiel: Wenn Preis in 15‚ÄØmin \>3% steigt *und* Volumen-Kriterium erf√ºllt ist, generiert die Engine ein BUY-Signal[\[33\]][\[34\]].)

* **Risikomanager:** Empf√§ngt neue Signal-Events als **Safety-Layer** vor jeder Ausf√ºhrung. Er pr√ºft mehrstufig alle vordefinierten Limits ‚Äì z.‚ÄØB. maximale Positionsgr√∂√üe pro Trade, Gesamt-Exposition aller offenen Trades, Tagesverlust-Limit, Stop-Loss-Grenzen sowie Auff√§lligkeiten im Markt[\[35\]][\[36\]]. Ist das Signal *konform*, publiziert der Risikomanager ein **Order-Event** (Freigabe zur Ausf√ºhrung) auf dem Bus; √ºberschreitet das Signal ein Limit, wird es **blockiert** und stattdessen ein **Alert-Event** (Warnung) erzeugt[\[37\]]. Au√üerdem √ºberwacht dieser Service globale **Circuit-Breaker**: Bei z.‚ÄØB. ‚â•5% Tagesverlust stoppt er den Handel komplett und l√∂st einen Alarm aus[\[38\]][\[39\]].

* **Execution-Service:** H√∂rt auf freigegebene Order-Events und f√ºhrt die Trades an der B√∂rse aus (√ºber die MEXC-API, z.‚ÄØB. mittels CCXT-Bibliothek)[\[40\]]. Nach Orderplatzierung verarbeitet der Service das Ergebnis ‚Äì ob Ausf√ºhrung (Fill) oder Fehler ‚Äì und publiziert ein **OrderResult-Event** zur√ºck auf den Bus[\[41\]]. Damit werden alle beteiligten Module informiert (f√ºr Trade-Buchung, Risikoupdate, Benachrichtigung). Der Execution-Service k√ºmmert sich um robuste Durchf√ºhrung: z.‚ÄØB. Wiederholungsversuche bei Timeouts und Idempotenz (Vermeidung von Doppelorders durch eindeutige client\_id)[\[41\]].

* **Persistenz-Service (Signal-Writer):** Dieser optionale Service (teils auch in die anderen integriert) sorgt f√ºr das **Persistieren wichtiger Ereignisse** in der Datenbank. Er kann relevante Events vom Bus abonnieren (Signals, Orders, Trades, Alerts) und schreibt sie in die entsprechenden Tabellen[\[42\]]. So entsteht ein Audit-Log aller Aktivit√§ten. In der aktuellen Implementierung werden z.‚ÄØB. alle generierten Signale, ausgef√ºhrten Trades und Risk-Entscheidungen gespeichert (siehe Abschnitt *Datenbank*).

* **Benachrichtigungs-Service:** Wartet auf Alert-Events oder wichtige Trade-Events und versendet **Push-Benachrichtigungen** an den Nutzer[\[43\]]. Kritische Meldungen (z.‚ÄØB. Not-Stopp ausgel√∂st, Order abgelehnt) werden sofort als Push geschickt, weniger dringende Infos nur im Dashboard angezeigt. (Dieser Service ist konzeptionell vorgesehen ‚Äì derzeit k√∂nnen Alerts z.‚ÄØB. via Web-Push im UI oder logischerweise via Telegram erfolgen, wobei Telegram laut Konzept deprecated ist[\[10\]].)

* **Dashboard / UI-Service:** Stellt eine Web-Oberfl√§che bereit, um den **Echtzeit-Status** des Bots einzusehen und ggf. Aktionen manuell durchzuf√ºhren. Das Dashboard (z.‚ÄØB. Prototyp als Streamlit-App) zeigt offene Positionen, P\&L, letzte Signale/Trades, Risk-Alerts etc. an[\[44\]]. Es abonniert daf√ºr die Bus-Events oder fragt periodisch die Datenbank. Zudem bietet das UI Kontrollfunktionen wie einen **‚ÄúNot-Aus‚Äù**\-Schalter, um alle Handelsaktivit√§ten sofort zu stoppen[\[45\]]. (Im MVP ist das UI optional und kann sp√§ter hinzugef√ºgt werden.)

Alle diese Services kommunizieren **asynchron √ºber den Message-Bus** (typischerweise Redis Pub/Sub) nach dem **Publish/Subscribe-Muster**[\[30\]]. Dadurch sind sie lose gekoppelt und unabh√§ngig deploybar ‚Äì ein Dienstausfall legt nicht das Gesamtsystem lahm, sondern Nachrichten stauen sich h√∂chstens im Bus und der Dienst kann neu starten, ohne Zustandsverlust[\[46\]].

**Event-getriebene Kommunikation:** Die zentrale Rolle spielt der Redis-Bus mit definierten **Topics** (Kan√§len). Die wichtigsten Topics und ihre Publisher/Subscriber sind in der folgenden Tabelle dargestellt (vgl. ARCHITEKTUR.md):

| Topic | Publisher | Subscriber | Inhalt (Kurz) |
| :---- | :---- | :---- | :---- |
| market\_data | Datenfeed-Service | Strategie-Engine, UI | Marktdaten (Preis, Volumen, Symbol, etc.) |
| signals | Strategie-Engine | Risikomanager | Handelssignal (Symbol, Richtung, Konfidenz, Grund) |
| orders | Risikomanager (Freigabe) | Execution-Service | Order-Anforderung (Symbol, Side, Menge, ggf. SL/TP) |
| order\_result | Execution-Service | Risikomanager, UI, Notify, Persistenz | Ausf√ºhrungsergebnis (Order-ID, Status, Preis, Fills, Fehler) |
| alerts | Risk/Execution/Monitoring | Notify-Service, UI, Persistenz | Alarmmeldung (Level, Code, Nachricht, Kontext) |
| health | *alle Dienste* | Monitoring/UI | Health-Status der Dienste (Name, Status, Zeit) |

*Quelle: Topics gem√§√ü Architektur[\[47\]][\[48\]].*

Diese **Message-Bus-Topologie** (hier auf Redis umgesetzt) erm√∂glicht einen entkoppelten, skalierbaren Event-Flow. Jeder Service h√∂rt nur auf die f√ºr ihn relevanten Events und ignoriert andere. Neue Komponenten (z.‚ÄØB. ein ML-basiertes Modul) k√∂nnen einfach durch Subscriben/Publizieren zus√§tzlicher Topics integriert werden, ohne dass bestehende Komponenten ge√§ndert werden m√ºssen.

**Start-Reihenfolge der Dienste:** Beim Neustart des gesamten Systems ist die richtige Sequenz wichtig, damit kein Dienst ins Leere l√§uft. Zuerst m√ºssen die **Infrastruktur-Services** verf√ºgbar sein: **Redis** (Pub/Sub-Bus) und die **PostgreSQL-Datenbank**. Erst danach sollten die anwendungsbezogenen Container hochgefahren werden. Praxisgerecht √ºbernimmt docker-compose dies via Abh√§ngigkeiten: So startet cdb\_signal (Signal-Engine) erst, wenn Redis l√§uft und der Datenfeed (cdb\_ws) Daten liefert[\[11\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L178-L186). Der Risk-Manager wartet auf die Signal-Engine[\[25\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L206-L214), und der Execution-Service wiederum auf den Risk-Manager *und* die Datenbank[\[20\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L236-L244). Dieses gestaffelte Hochfahren stellt sicher, dass z.‚ÄØB. die Signal-Engine beim Start direkt auf den Redis-Bus verbinden kann und auch bereits Marktdaten-Events vorfindet, oder dass der Execution-Service eine Datenbankverbindung herstellen kann, weil Postgres bereit ist. Sollte ein Dienst dennoch zu fr√ºh gestartet sein (etwa Redis Verz√∂gerung), besitzen die Services Wiederholungs- bzw. Backoff-Logik, um die Verbindung erneut zu versuchen[\[49\]][\[50\]] (z.‚ÄØB. reconnect beim WebSocket-Datenfeed). Insgesamt gilt: **Redis und DB zuerst**, dann *Datenfeed ‚Üí Strategie ‚Üí Risiko ‚Üí Execution ‚Üí optionale UI/Notify*.

## 4\. Datenbank (PostgreSQL Setup & Schema)

F√ºr Persistenz und Nachvollziehbarkeit betreibt Claire de Binaire eine **PostgreSQL**\-Datenbank. Das SQL-Schema ist in der Datei *DATABASE\_SCHEMA.sql* festgelegt und wird beim Neuaufsetzen automatisch angewendet (durch Mounten der SQL-Datei ins Postgres-Container-Initdir[\[19\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L38-L44)). Wichtig: Vor dem ersten Start m√ºssen die in .env definierten DB-Zugangsdaten stimmen, damit der Container die DB erstellen kann (POSTGRES\_USER, POSTGRES\_PASSWORD, POSTGRES\_DB[\[8\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L32-L40)). Der Datenbankname ist standardm√§√üig **claire\_de\_binare** (ohne Accent)[\[51\]] ‚Äì dieser muss konsistent verwendet werden.

Nach dem Start enth√§lt die Datenbank das Schema mit allen notwendigen Tabellen und ggf. Basisdaten. Die wichtigsten Tabellen aus *DATABASE\_SCHEMA.sql* sind:

* **signals** ‚Äì Enth√§lt alle generierten **Trading-Signale** der Strategie-Engine[\[52\]]. Pro Eintrag: fortlaufende ID, Symbol, Side (BUY/SELL), Confidence (Konfidenzwert 0‚Äì1), Reason (Begr√ºndungstext), Preis zum Signalzeitpunkt, Prozent√§nderung, Volumen sowie Zeitstempel. Indexe bestehen u.a. auf Symbol und Timestamp f√ºr schnelle Abfragen.

* **trades** ‚Äì Beinhaltet ausgef√ºhrte **Trades** (Einstiege/Ausstiege)[\[53\]]. Verkn√ºpft ggf. auf das Signal (signal\_id), enth√§lt Menge, Entry/Exit-Preise, PnL (Profit/Loss absolut und %), Status (OPEN/CLOSED), zugeordnete Order-IDs usw. Hier werden alle abgeschlossenen Trades zu Audit-Zwecken archiviert.

* **risk\_events** ‚Äì Protokolliert Entscheidungen des **Risikomanagers**[\[54\]]. Zum Beispiel wenn ein Signal geblockt wurde (blocked\_order=true) oder ein Circuit Breaker gegriffen hat. Enth√§lt Feld severity (INFO/WARNING/CRITICAL) und eine Beschreibung des Ereignisses (z.‚ÄØB. *‚ÄúTagesverlust-Limit √ºberschritten ‚Äì Handel gestoppt‚Äù*).

* **orders** ‚Äì H√§lt die Historie aller **Order-Anfragen** und deren Status[\[55\]] (PENDING, FILLED, PARTIALLY\_FILLED, CANCELLED, REJECTED). Hier werden auch ggf. Exchange-spezifische IDs, Zeitstempel der Orderaufgabe und Ausf√ºhrung etc. gespeichert. Damit l√§sst sich jeder Order-Lebenszyklus nachvollziehen.

* **Weitere Tabellen:** positions f√ºr aktuell offene Positionen (f√ºr die Berechnung der Gesamt-Exposition)[\[56\]], balances f√ºr regelm√§√üige Kapital-Snapshots (Equity, Margin, PnL)[\[57\]], health\_checks f√ºr periodische Service-Health-Status[\[58\]], metrics f√ºr Performance-Metriken[\[59\]] (z.‚ÄØB. durchschnittliche Signal-Konfidenz, Verarbeitungszeiten) sowie strategy\_params zur Historisierung von Strategie-Parameter√§nderungen[\[60\]].

Beim erstmaligen Aufsetzen werden durch das Schema-Skript auch einige **Initialdaten** eingetragen ‚Äì z.‚ÄØB. Standard-Parameter in strategy\_params (Momentum-Schwelle, max. Drawdown etc.)[\[61\]] ‚Äì sowie Berechtigungen gesetzt. So wird ein DB-Benutzer (z.‚ÄØB. ‚Äûclaire‚Äú bzw. der in POSTGRES\_USER gesetzte User) berechtigt, die Tabellen zu selektieren und zu ver√§ndern[\[62\]]. Au√üerdem wird eine schema\_version Tabelle angelegt, in der die Schema-Version (‚Äû1.0‚Äú) vermerkt ist[\[63\]]. F√ºr zuk√ºnftige √Ñnderungen k√∂nnten hier Migrationen versioniert werden.

**Migration/Updates:** Sollte das System neu aufgesetzt werden, aber eine bestehende Datenbank mit √§lteren Daten vorhanden sein, ist darauf zu achten, dass das Schema kompatibel ist. Im Zweifel k√∂nnen Migrationen erforderlich sein, um alte Tabellenversionen an das neue Schema anzupassen (dies w√ºrde √ºber Erh√∂hung der schema\_version und separate Migration-Skripts passieren). Im vorliegenden Schema 1.0 sind jedoch alle oben genannten Tabellen frisch anzulegen, ein Neuaufsetzen mit leerer DB ist daher unkompliziert.

**Persistierte Signale & Events:** Alle wichtigen Events des Bots werden in der DB persistiert, um **Transparenz und Auditierbarkeit** zu gew√§hrleisten. Beim Neuaufsetzen auf einem frischen Server sollten vorhandene historische Daten (Signals, Trades etc.) nach M√∂glichkeit aus Backups wiederhergestellt werden, um den fortlaufenden Betrieb mit Historie zu erm√∂glichen. Andernfalls startet das System mit leeren Tabellen ‚Äì was funktional kein Problem ist (der Bot kann auch ohne historische Daten handeln), aber man verliert die Bezugswerte f√ºr z.‚ÄØB. Tages-Drawdown-Berechnung, offene Positionen etc. Im Abschnitt *Sicherheit & Recovery* sind Backup/Recovery-Prozesse erl√§utert, um persistierte Events zu sichern. Kurz gesagt: **Vor dem Neuaufsetzen immer ein Backup der DB ziehen**, damit keine Signale/Trades verloren gehen.

## 5\. Event-Handling (Event-Bus & Subscriptions)

Die **ereignisgetriebene Kommunikation** erfolgt √ºber den zentralen **Message-Bus (Redis)**. Alle Services sind darauf ausgelegt, bestimmte Topics zu **subscriben** (abonnierten) und darauf Ereignisse zu **publizieren**, gem√§√ü ihrer Rolle. Die Integration ist im Code typischerweise √ºber die Redis-Pub/Sub-API realisiert (z.‚ÄØB. via redis-py Library). Jedes Event wird als JSON-Objekt verschickt, oftmals validiert durch ein gemeinsames Schema (siehe EVENT\_SCHEMA.json). Dieses JSON-Schema definiert die erwarteten Felder und Typen pro Event-Typ, was Konsistenz sicherstellt ‚Äì z.‚ÄØB. ein Signal-Event muss type \= "signal", ein Symbol, Timestamp, side (BUY/SELL) und confidence 0‚Äì1 enthalten[\[64\]]. Solche formalen Schemabeschreibungen k√∂nnen genutzt werden, um Eingaben fr√ºh zu pr√ºfen und Fehlformate abzufangen.

Im laufenden Betrieb fungiert Redis als **verteilter Event-Bus**: Ein Publisher schreibt z.‚ÄØB. eine neue Nachricht auf Topic "signals" ‚Äì Redis leitet diese sofort an alle Services weiter, die "signals" abonniert haben. Unten eine Zusammenfassung, welche Services welche Topics bearbeiten (siehe auch Tabelle in Abschnitt 3):

* **Topic market\_data:** Publiziert vom Datenfeed-Service mit den neuesten Marktdaten (z.‚ÄØB. Preisaktualisierungen). Abonniert von der Strategie-Engine (zur Signalberechnung) und ggf. vom Dashboard (f√ºr Charts)[\[65\]].

* **Topic signals:** Publiziert von der Strategie-Engine, sobald ein neues Handelssignal erkannt wurde. Nur der Risikomanager subscribed auf signals, da er als n√§chstes jeden Signal verarbeitet[\[65\]].

* **Topic orders:** Publiziert vom Risikomanager, wenn ein Signal freigegeben wurde (Order-Anforderung). Nur der Execution-Service abonniert orders und f√ºhrt diese Order dann aus[\[66\]]. (Nicht freigegebene Signale erzeugen stattdessen einen Alert, siehe dort.)

* **Topic order\_result:** Publiziert vom Execution-Service nach Ausf√ºhrung einer Order ‚Äì enth√§lt entweder die Best√§tigung eines Trades oder eine Fehlermeldung[\[67\]]. Abonniert vom Risikomanager (zur Kenntnisnahme des Ergebnisses, z.‚ÄØB. f√ºr PnL-Berechnung oder Fehlermeldung), vom Benachrichtigungs-Service (um z.‚ÄØB. *Trade ausgef√ºhrt* Push zu senden) und vom UI (zur Aktualisierung der Oberfl√§che)[\[68\]]. Auch ein Persistenz-Service w√ºrde hier mitlauschen, um Trades in die DB zu schreiben.

* **Topic alerts:** Publiziert von verschiedenen Stellen, insbesondere dem Risikomanager (wenn er ein Signal blockiert oder einen globalen Stopp ausl√∂st) oder vom Execution-Service (bei kritischen Fehlern). Abonniert vom Notify-Service und UI, die solche Alerts dem Benutzer anzeigen[\[69\]]. Auch hier kann Persistenz die Alerts loggen.

* **Topic health:** Publiziert von *jedem* Service in regelm√§√üigen Abst√§nden oder auf Anfrage, um den eigenen Gesundheitsstatus zu melden. Abonniert z.‚ÄØB. vom Dashboard oder einem Monitoring-Service, um den Gesamtzustand aller Dienste zu √ºberwachen[\[70\]]. Im Compose-Setup erfolgt Health-Checking allerdings prim√§r durch Docker-Mechanismen (siehe Healthcheck in Dockerfile/Compose).

Die Event-Nachrichten selbst sind JSON-Strukturen mit festgelegten Feldern. Ein **Beispiel**: Ein Signal-Event k√∂nnte wie folgt aussehen:

{
  "type": "signal",
  "symbol": "BTC\_USDT",
  "timestamp": 1696789260,
  "side": "BUY",
  "confidence": 0.85,
  "reason": "Momentum-Kaufsignal (+5%/15min, hohes Volumen)"
}

Hier signalisiert die Strategie-Engine einen Kaufsignal f√ºr BTC/USDT mit 85% Confidence und nennt als Grund den Momentum-Anstieg. Der Risikomanager w√ºrde dieses Event aus dem Redis-Stream lesen und entsprechend reagieren. √Ñhnlich standardisiert sind Order-Events (type: "order" mit Symbol, side, quantity, etc.), OrderResult-Events (status: FILLED/ERROR usw.) und Alerts (level: INFO/WARNING/CRITICAL mit Code und Message)[\[71\]].

**Implementierungsdetails:** In jedem Service l√§dt die Konfigurationsroutine die relevanten Bus-Parameter aus den Environment-Variablen (z.‚ÄØB. REDIS\_HOST, REDIS\_PORT, REDIS\_PASSWORD) ‚Äì im Standard sind Host "redis" und Port 6379 gesetzt[\[7\]], Passwort muss aus .env kommen. Die Services stellen beim Start die Verbindung zu Redis her. Gelingt das nicht (Redis noch nicht bereit), wird meist in Intervallen ein Retry unternommen, wie oben erw√§hnt. Sobald verbunden, f√ºhren die Services ein **Subscribe** auf ihre Topics durch (bspw. Strategie abonniert market\_data, Risk abonniert signals usw.) und lauschen in separaten Threads oder Async-Callbacks auf neue Events. Beim Eintreffen eines Events wird dieses deserialisiert (JSON \-\> Objekt) und der jeweilige **Event-Handler** im Service greift die Daten auf (z.‚ÄØB. Risiko pr√ºft Limits bei Signal, Execution f√ºhrt Order bei Order-Event aus). Publizieren wiederum erfolgt nach Bearbeitung analog: der Service serialisiert das Event-Objekt zu JSON und pusht es auf den Redis-Kanal.

Durch diese Architektur sind die Services entkoppelt: Die Kommunikation ist **asynchron** und erfolgt in **Echtzeit**. Sollte ein Service ausfallen, puffert Redis die Nachrichten nicht (Pub/Sub verteilt nur live), aber dank der kurzen Abfolgen (Marktdaten alle Sekunde, Signale alle paar Minuten) ist ein Wiederverbinden unproblematisch ‚Äì verpasste Events sind entweder nicht kritisch oder k√∂nnen durch erneute Marktdaten schnell nachgeliefert werden. F√ºr wichtige Events k√∂nnte man Redis Streams oder eine Message-Queue mit Persistenz einsetzen (in Zukunft evtl. NATS, RabbitMQ, Kafka), aber im aktuellen Setup gen√ºgt der Redis Pub/Sub (MVP-Ansatz)[\[30\]][\[49\]].

Zusammengefasst: **Der Event-Bus nach dem Pub/Sub-Prinzip ist das R√ºckgrat der Systemkommunikation.** Das EVENT\_SCHEMA.json stellt sicher, dass alle Services dieselbe Sprache sprechen, und in ARCHITEKTUR.md bzw. obiger Tabelle ist klar dokumentiert, welcher Dienst welche Events produziert oder konsumiert ‚Äì ein essenzielles Nachschlagewerk beim Neuaufsetzen, um nichts zu vergessen.

## 6\. Servicespezifikationen (Beispiele: Strategy, Risk, Signal-Writer, Execution)

In diesem Abschnitt werden exemplarisch einige zentrale Services im Detail beschrieben ‚Äì inklusive Konfiguration, Ablauf und wie sie dem allgemeinen Service-Template entsprechen. Jeder Service folgt dem gleichen Grundaufbau (siehe *SERVICE\_TEMPLATE.md*): ein eigenes Verzeichnis mit service.py (Hauptlogik), config.py (Konfigurationsladen von ENV), optionalen Hilfsmodulen (models.py f√ºr Datenklassen, etc.) und einem README[\[72\]]. Alle Services implementieren bestimmte Pflichtfunktionen: einen **HTTP-Healthcheck** (/health Endpoint), **strukturiertes Logging** (JSON-Format Logs), **Graceful Shutdown** via Signal-Handler und **Konfigurationsvalidierung** beim Start[\[73\]]. Dadurch verhalten sich die Services konsistent und sind im Betrieb leicht zu √ºberwachen.

**Strategie-Engine (Signal-Generator):** Dieser Service verantwortet die **Handelsstrategie**. Er liest kontinuierlich Marktdaten vom market\_data Topic (abonniert z.B. auf Kurse von BTC/USDT, ETH/USDT etc.) und berechnet definierte Regeln/Indikatoren. In der aktuellen Implementierung handelt es sich um eine einfache **Momentum-Strategie**: Es wird z.‚ÄØB. gepr√ºft, ob der Preis eines Coins in den letzten *LOOKBACK\_MIN* Minuten um mehr als einen Schwellwert X% gestiegen/gesunken ist und ob das Volumen √ºber einem Minimum liegt. Ist die Bedingung erf√ºllt, generiert die Strategie ein entsprechendes Kauf- oder Verkaufssignal. Standardm√§√üig ist die **Schwelle 3%** Preis√§nderung bei mindestens **100k Volumen**, was dann eine Confidence-Berechnung triggert[\[33\]][\[74\]]. Die Strategie-Engine erstellt ein Signal-Objekt (siehe Event oben) und ver√∂ffentlicht es auf dem signals Kanal.

Konfigurierbar ist das Verhalten √ºber ENV-Variablen: z.‚ÄØB. SIGNAL\_THRESHOLD\_PCT (Momentum-Schwelle, Default 3.0) und SIGNAL\_MIN\_VOLUME (Mindestvolumen)[\[74\]]. Diese k√∂nnen in der .env angepasst werden, um die Empfindlichkeit der Strategie zu steuern. Die Engine loggt ihre Aktionen, z.B. *‚ÄúSubscribed to Topic: market\_data‚Äù* und bei Start die gesetzten Parameter[\[75\]]. Sie bietet zudem HTTP-Endpoints: /health (einfacher Ok-Check), /status (Status/Statistik der Signals, z.‚ÄØB. Anzahl generierter Signale, letztes Signal)[\[76\]], /metrics (Prometheus-Metriken, falls integriert). Dies hilft beim Monitoring und Testing. Die Signal-Engine l√§uft kontinuierlich, d.h. es gibt eine Schleife oder einen Redis-Listener, der auf neue Marktdaten reagiert, und zwischenzeitlich berechnet sie Indikatoren (z.‚ÄØB. alle 1 Minute).

**Risikomanager:** Der Risk-Service implementiert die **mehrlagige Risikokontrolle** des Systems. Er empf√§ngt jedes Signal vom signals Topic und pr√ºft nacheinander alle hinterlegten Regeln, bevor eine Order zum Exchange durchgewunken wird. Die konfigurierbaren **Schwellenwerte** sind in ENV definiert (teils mit Default): MAX\_POSITION\_PCT (max. Positionsgr√∂√üe pro Trade, default 10% des Kapitals)[\[77\]], MAX\_EXPOSURE\_PCT (max. Gesamt-Exposition, default 50%)[\[78\]], STOP\_LOSS\_PCT (Stop-Loss pro Trade, default 2%)[\[79\]], MAX\_DAILY\_DRAWDOWN\_PCT (max. Tagesverlust, default 5%)[\[79\]]. Diese Werte sollte man vor Inbetriebnahme gem√§√ü Risikoprofil setzen. Beim Eintreffen eines Signals durchl√§uft der Risikomanager folgende Logik (Pseudocode gek√ºrzt aus *Risikomanagement-Logik.md*): zuerst globale Abbruchkriterien, dann trade-spezifische Limits[\[80\]][\[81\]]. In vereinfachter Form:

1. **Tagesverlust-Limit √ºberschritten?** Wenn ja, **alle Trades stoppen** f√ºr den Tag (Circuit Breaker) ‚Äì Signal wird verworfen, bestehende Positionen geschlossen, Alert *‚ÄúTagesverlust-Limit √ºberschritten ‚Äì Handel gestoppt‚Äù* wird publiziert[\[82\]][\[83\]].

2. **Anormale Marktbedingungen?** (z.‚ÄØB. Exchange nicht erreichbar, extreme Volatilit√§t \>10% in 5min) ‚Äì dann **Handel pausieren**, Signal verwerfen, Alert *‚ÄúTrading ausgesetzt wegen Marktanomalie‚Äù*[\[84\]].

3. **Expositions-/Positionsanzahl-Limit?** Wenn bereits zu viele offene Positionen oder zu viel Kapital im Markt, wird das neue Signal **abgelehnt** und ein entsprechender Alert geloggt[\[85\]].

4. **Positionsgr√∂√üe \> Max?** Wenn die vorgeschlagene Order gr√∂√üer als erlaubt, wird sie **beschnitten** auf das erlaubte Maximum[\[86\]]. D.h. der Risikomanager √§ndert die Quantity auf z.‚ÄØB. 10% des Kapitals und l√§sst das angepasste Signal passieren (optional mit Warn-Alert *‚ÄúSignalgr√∂√üe angepasst‚Äù*).

5. **Sonst:** Wenn all diese Checks bestanden sind, wird das Signal **freigegeben**[\[87\]]. Der Risikomanager erzeugt dann ein **Order-Event** auf dem Bus, das alle relevanten Orderdaten enth√§lt (Symbol, Side, Gr√∂√üe, evtl. Stop-Loss).

Zus√§tzlich √ºberwacht der Risikomanager laufend ge√∂ffnete Trades: sollte z.‚ÄØB. im Verlauf ein Trade einen Verlust \> Stop-Loss-PCT erreichen, wird ein Close-Event initiiert (Position sofort schlie√üen)[\[83\]]. Ebenso, wenn der kumulative Tagesverlust √ºber das Limit steigt, greift der Circuit Breaker jederzeit ‚Äì nicht nur bei neuen Signalen[\[88\]]. Die Regeln sind hierarchisch priorisiert (Tagesverlust und extreme Bedingungen ganz oben)[\[89\]], sodass immer die gravierendste Schutzma√ünahme zuerst greift.

Der Risikomanager loggt alle Entscheidungen. Blockierte Signale resultieren in risk\_events\-DB-Eintr√§gen (mit Beschreibung, z.B. *‚ÄúExpositions-Limit erreicht ‚Äì Signal verworfen‚Äù*) und Alerts. Freigegebene Signale sieht man indirekt durch die nachfolgenden Trades. Auch dieser Service bietet HTTP-Status (z.‚ÄØB. Anzahl erhaltene Signale, genehmigte vs. abgelehnte Orders)[\[90\]] und Health-Check. Beim Start loggt er die gesetzten Limits (*‚ÄúMax Position: 10.0%‚Äù* etc.)[\[91\]], damit klar ist, mit welchen Parametern er arbeitet.

**Execution-Service:** Diese Komponente f√ºhrt die **Orderausf√ºhrung** aus. Sie wartet auf orders Events, die vom Risikomanager kommen. Bei Eintreffen entpackt sie die Orderdaten und interagiert mit der **MEXC-B√∂rsen API**, typischerweise √ºber eine Bibliothek wie *CCXT*, welche g√§ngige Methoden bereitstellt (z.‚ÄØB. create\_order(...)). In der aktuellen Phase war die Execution in Entwicklung; konzipiert ist, dass der Service sowohl Market-Orders als auch Limit/Stop je nach Bedarf platzieren kann. Wichtig: Die **API-Keys** m√ºssen korrekt konfiguriert sein (MEXC\_API\_KEY/SECRET), und es sollte das **Testnet** oder ein beschr√§nktes Konto verwendet werden, um Risiken zu minimieren.

Nach Absetzen der Order wartet der Execution-Service auf die Best√§tigung von der B√∂rse (bzw. erh√§lt √ºber WebSocket oder API-R√ºckmeldung den Orderstatus). Daraus generiert er dann ein **order\_result** Event: im Erfolgsfall mit Status "FILLED" und Details (gef√ºllte Menge, Preis)[\[92\]], im Fehlerfall mit Status "ERROR"/"REJECTED" und einer Fehlermeldung. Dieses Event publiziert er auf dem Bus, damit alle anderen Module es verarbeiten. Beispielsweise erkennt der Risikomanager daran, dass eine Position nun offen ist oder dass ein Trade fehlgeschlagen ist und loggt ggf. einen Risk-Event. Das UI w√ºrde den neuen Trade anzeigen oder eine Fehlermeldung visualisieren.

Der Execution-Service muss robust sein gegen√ºber **Netzwerkausf√§llen oder API-Errors**. Implementiert ist vorgesehen: falls keine Antwort innerhalb eines Timeouts kommt, Wiederholungsversuche (mit Backoff) zu senden[\[93\]]. Dabei hilft Idempotenz: jedem Order-Event wird vorab ein eindeutiger client\_id mitgegeben[\[94\]], sodass die Execution erkennen kann, ob ein Retry dieselbe Order betrifft und nicht doppelt ausgef√ºhrt werden darf. Die Execution-Komponente schreibt erfolgreiche Trades in die Datenbank (Tabelle trades) und aktualisiert ggf. positions und balances. In Compose ist sie so konfiguriert, dass sie auf Postgres wartet[\[20\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L236-L244), damit die DB-Verbindung steht. Logs des Execution-Services enthalten u.a. Order-Requests, R√ºckmeldungen der B√∂rse und etwaige Exception-Traces bei Fehlern. Auch hier gibt es einen /health Endpoint.

**Signal-Writer / Persistenz:** In der aktuellen Architektur gibt es (noch) keinen separaten Persistenz-Container; stattdessen √ºbernehmen die bestehenden Services die Aufgabe, relevante Daten in die DB zu schreiben. So kann z.‚ÄØB. der Signal-Generator jeden generierten Signal in die signals\-Tabelle einf√ºgen, und der Execution-Service jeden ausgef√ºhrten Trade in trades. Der Risk-Manager k√∂nnte alle Alerts/Risk-Events in risk\_events loggen. Dieser Ansatz wurde wahrscheinlich f√ºr das MVP gew√§hlt, um Komplexit√§t zu sparen (kein separater Service n√∂tig). Perspektivisch ist aber ein **dedizierter Persistenz-Service** sinnvoll, wie in der Architektur vorgesehen[\[42\]]. Dieser w√ºrde sich auf Topics wie signals, order\_result, alerts subscriben und alle Ereignisse parallel in der DB abspeichern (als Audit-Trail). Beim Neuaufsetzen ist es wichtig zu wissen: **Datenpersistenz l√§uft √ºber die DB** ‚Äì es gibt keine andere Statefulness in den Services selbst. Wenn also die DB intakt aus einem Backup wiederhergestellt wird und die Services neu starten, haben sie den vollen Verlauf (z.‚ÄØB. offene Positionen k√∂nnen aus positions gelesen werden). Falls die DB verloren ginge, startet der Bot ‚Äúfrisch‚Äù ‚Äì was man nur in Ausnahmef√§llen m√∂chte.

Alle Services orientieren sich am gemeinsamen **Service-Template** (einheitlicher Aufbau und Grundfunktionen)[\[73\]], was den Betrieb vereinfacht: z.‚ÄØB. reagiert jeder Dienst auf SIGTERM mit einem sauberen Shutdown (Connection Close, Thread Stop) gem√§√ü implementiertem Signal-Handler, und jeder Dienst nutzt strukturiertes Logging √ºber die Python logging Bibliothek (Format im JSON-Stil). Dadurch sind Logs zentral auswertbar. Ebenso pr√ºfen die Services bei Start die wichtigsten ENV-Variablen ‚Äì z.‚ÄØB. ob Redis-Host gesetzt, Port g√ºltig, Limits sinnvoll ‚Äì und werfen Fehler, falls Konfigurationsfehler vorliegen[\[95\]][\[96\]]. Dies verhindert h√§ufige Fehlkonfigurationen beim Deployment.

## 7\. Tests und Debugging (End-to-End Tests & Diagnose)

Nach dem Aufsetzen des Systems sollte ein **End-to-End-Test** durchgef√ºhrt werden, um sicherzustellen, dass alle Komponenten ordnungsgem√§√ü funktionieren. Hierf√ºr liegt die Anleitung *END\_TO\_END\_TEST\_GUIDE.md* vor, die Schritt f√ºr Schritt das Vorgehen beschreibt. Wichtige Punkte daraus:

* **Container-Start pr√ºfen:** Zun√§chst wird via docker-compose up \-d das Gesamtsystem gestartet. Erwartet wird, dass alle definierten Container hochfahren und den Status "healthy" erreichen[\[97\]]. Konkret sollten mindestens Redis, PostgreSQL, Signal-Engine und Risk-Manager laufen (im Entwicklungsstand ggf. plus der Datenfeed cdb\_ws). In Docker Desktop kann man dies visuell kontrollieren; alternativ per docker ps.

* **Logs beobachten:** F√ºr jeden Service sollten die Logs keine Fehler anzeigen. Die Test-Anleitung empfiehlt, in Docker Desktop oder via docker logs \<container\> die Ausgaben zu verfolgen[\[98\]]. Typische Meldungen f√ºr einen erfolgreichen Start sind z.‚ÄØB.:

* *Signal-Engine:* ‚ÄûRedis verbunden: redis:6379‚Äú, ‚ÄûSubscribed zu Topic: market\_data‚Äú, ‚ÄûüöÄ Signal-Engine gestartet (Schwelle: 3.0%)‚Äú[\[75\]].

* *Risk-Manager:* ‚ÄûRedis verbunden: redis:6379‚Äú, ‚ÄûSubscribed zu Topic: signals‚Äú, ‚ÄûüöÄ Risk-Manager gestartet (Max Position: 10.0% ...)‚Äú[\[91\]].

* Datenfeed (cdb\_ws): Meldet Verbindung zur B√∂rse und dass MarketData-Events publiziert werden (z.‚ÄØB. Top Movers alle X Sekunden).
  Fehlermeldungen (ERROR im Log) d√ºrfen **nicht** auftauchen[\[99\]]. Falls doch, m√ºssen sie untersucht werden (z.‚ÄØB. Redis-Verbindung fehlgeschlagen, weil falsches Passwort).

* **Health-Checks:** Als N√§chstes ruft man die Health-URLs der Services ab (z.‚ÄØB. http://localhost:8001/health f√ºr Signal, 8002/health f√ºr Risk) ‚Äì entweder im Browser, via Curl oder wie im Guide gezeigt mit PowerShells Invoke-WebRequest[\[100\]]. Erwartet wird jeweils ein JSON {"status":"ok", ...} mit HTTP 200[\[101\]]. Ein ausbleibendes OK deutet auf ein Service-Problem hin (dann Logs checken).

* **Redis-Events √ºberpr√ºfen:** Man kann in den Redis-Container reinschauen: docker exec \-it cdb\_redis redis-cli und dort MONITOR eingeben[\[102\]]. Damit sieht man alle Pub/Sub-Aktivit√§ten live. Im erfolgreichen Betrieb sollte im Sekundentakt ein PUBLISH "market\_data" ... auftauchen[\[103\]] (der Datenfeed sendet kontinuierlich Marktdaten). Zudem sp√§testens nach einigen Momenten erste PUBLISH "signals" ... und ggf. orders wenn Signale freigegeben wurden. Das zeigt, dass die gesamte Pipeline vom Datenfeed √ºber Strategie zu Risk funktioniert. Anschlie√üend CTRL+C in Redis CLI, um den Monitor zu verlassen.

* **Datenbankinhalte pr√ºfen:** Mit docker exec \-it cdb\_postgres psql \-U \<USER\> \-d claire\_de\_binare kann man sich auf die DB schalten[\[104\]]. Dort lassen sich Abfragen durchf√ºhren, um zu sehen, ob Daten ankommen. Beispielsweise die Anzahl der Signals: SELECT COUNT(\*) FROM signals; ‚Äì nach ein paar Minuten Laufzeit sollte \>0 herauskommen[\[105\]]. Oder man schaut die letzten Eintr√§ge an (SELECT \* FROM signals ORDER BY timestamp DESC LIMIT 5;). Die Anleitung gibt hier konkrete SQL-Beispiele, etwa um die letzten 5 Signale mit Zeitstempel anzuzeigen[\[106\]], oder Risk-Events und eine Zusammenfassung aller Kernzahlen (Anzahl Signale, Risk-Events, offene Trades, Gesamtorders)[\[107\]]. Diese Queries sollten Ergebnissen liefern (z.‚ÄØB. einige Signale und ggf. Risk-Events, falls Limits gerissen wurden). Stimmen die Zahlen nicht (z.‚ÄØB. 0 Signale trotz Marktdaten), stimmt etwas im vorherigen Schritt nicht.

* **Service-Metriken:** Die Guide schl√§gt ferner vor, die /status Endpoints abzufragen (sofern implementiert)[\[108\]][\[90\]]. Dort sieht man z.‚ÄØB. wie viele Signale generiert und wie viele Orders genehmigt/blockiert wurden ‚Äì ein direkter Indikator, ob die Strategie und der Risikomanager sinnvoll arbeiten. Beispielsweise k√∂nnte signals\_generated bei der Signal-Engine \>0 sein und orders\_approved beim Risk-Manager ebenfalls \>0 nach einiger Laufzeit[\[109\]].

Am Ende definiert der End-to-End-Test eine **Checkliste von Erfolgskriterien** (7/7 m√ºssen erf√ºllt sein)[\[110\]]:
1\. Alle Container laufen und sind *healthy*.
2\. Health-Checks der Services antworten mit 200 OK.
3\. Redis antwortet auf PING (Verbindung okay).
4\. PostgreSQL: notwendige Rollen/Benutzer vorhanden (Setup korrekt).
5\. PostgreSQL: Verbindung aus Container erfolgreich.
6\. Signal-Engine: Keine Errors, Health ok.
7\. Risk-Manager: Keine Errors, Health ok.

Wenn all das erf√ºllt ist, gilt der Test als bestanden[\[111\]] ‚Äì das System ist dann **vollst√§ndig einsatzbereit** (in der Doku beispielhaft am 21.10.2025 so vermerkt).

**Troubleshooting & Debugging:** Tritt irgendwo ein Problem auf, gibt es in den Dokumenten Hilfestellungen:

* Zuallererst sollte man die Container-Logs pr√ºfen (docker logs \<name\>), da hier meist bereits ersichtlich ist, wo es hakt (z.‚ÄØB. Exception wegen fehlender Umgebungsvariable oder Verbindungsfehler).

* In *CODE\_CLEANUP\_AUDIT.md* und *TROUBLESHOOTING.md* finden sich Checklisten: z.‚ÄØB. ob die .env\-Datei korrekt ist (keine Duplikate, alle Passw√∂rter konsistent)[\[112\]]. Ein docker-compose config Befehl kann Syntaxfehler in der Compose oder fehlende ENV anzeigen[\[113\]].

* H√§ufige Probleme beim Start: **Redis nicht erreichbar** ‚Äì dann den Redis-Container (neu) starten[\[114\]]; **Port-Kollision** ‚Äì wenn z.‚ÄØB. noch ein alter Prozess auf 8001 l√§uft, muss dieser beendet oder der Port ge√§ndert werden[\[114\]]; **fehlende ENV-Variablen** ‚Äì dann .env √ºberpr√ºfen und korrekt bef√ºllen[\[114\]].

* **Keine Marktdaten/Signale:** Pr√ºfen, ob der Datenfeed l√§uft (docker logs cdb\_ws) und ob dieser erfolgreich auf Redis publiziert (siehe Redis MONITOR). Gegebenenfalls sicherstellen, dass die API-Keys g√ºltig sind und das Netzwerk Zugriff auf MEXC hat.

* **Keine DB-Eintr√§ge:** Pr√ºfen, ob die Services DB-Verbindungsdaten haben (docker exec cdb\_signal env | grep POSTGRES beispielsweise)[\[115\]]. Fehlt hier etwas, dann .env falsch oder der Service wurde ohne DB-Anbindung gebaut. Testhalber kann man auch manuell ein Signal in Redis stellen, um die Verarbeitungskette zu stimulieren (siehe Guide: mit redis-cli ein Test-Event auf market\_data publizieren)[\[116\]].

* **Performance/Delay:** Wenn z.‚ÄØB. Signale generiert werden, aber Execution sp√§t reagiert, k√∂nnte die Bottleneck der Exchange API sein ‚Äì hier sind ggf. Ratenlimits zu beachten. Logs mit Timestamp helfen, solche Lags zu identifizieren.

Generell sollte man im Fehlerfall zun√§chst die spezifischen Komponenten pr√ºfen (oft ist es ein kleines Config-Detail). Die umfangreichen Dokumentationen (ARCHITEKTUR.md, End-to-End Guide, etc.) sind so gestaltet, dass sie f√ºr jedes Symptom m√∂gliche Ursachen bereitstellen.

## 8\. Sicherheit und Recovery (Risiken, Secrets, Backup, Rollback)

Beim Neuaufsetzen des Servers sind einige **Sicherheitsaspekte** und **Wiederanlauf-Strategien** zu beachten, um einen sicheren, nahtlosen Betrieb zu gew√§hrleisten:

**Risiken beim Neuaufsetzen:**
\- *Konfigurationsfehler:* Ein gro√ües Risiko ist, dass ENV-Secrets falsch eingegeben werden (z.‚ÄØB. vertippter API-Key, falsches DB-Passwort). Dies kann dazu f√ºhren, dass der Bot zwar startet, aber keine Trades ausf√ºhrt oder keine Daten empf√§ngt. L√∂sung: penible √úberpr√ºfung der .env gegen die Doku.
\- *Datenverlust:* Wird der Server neu aufgesetzt ohne vorheriges Backup, k√∂nnen alle **persistierten Signale, Trades und Parameter** verloren gehen. Dadurch gehen wichtige Referenzen f√ºr Risikometriken (z.‚ÄØB. bisheriger Tagesverlust) verloren. Au√üerdem w√§ren Audit-Logs weg, was **Transparenz** und Nachvollziehbarkeit beeintr√§chtigt. Daher immer **vor dem Neuaufsetzen Backups ziehen** (siehe unten).
\- *Secrets-Leaks:* W√§hrend des Neuaufsetzens ist darauf zu achten, dass **Schl√ºssel und Passw√∂rter** nicht in falsche H√§nde geraten. .env-Dateien sollen z.‚ÄØB. mittels restriktiver Dateirechte gesch√ºtzt sein[\[4\]]. Im Idealfall liegen Secrets in einem Vault und werden zur Deployzeit injected. Kein Secret sollte im Klartext in ein Repository committet werden.
\- *Unbeabsichtigte Withdrawals:* Sicherheitsprinzip ist ‚ÄûSicherheit vor Profit‚Äú ‚Äì d.h. selbst wenn der Server kompromittiert w√ºrde, d√ºrfen API-Keys keine Auszahlung erlauben[\[117\]]. Beim Neuaufsetzen stets API-Schl√ºssel ohne Withdraw-Rechte verwenden[\[4\]] und ggf. IP-Whitelist bei der B√∂rse aktivieren. So minimiert man das finanzielle Risiko.
\- *Ausfallrisiko:* W√§hrend der Neuinstallation steht der Bot ggf. kurz still. Wenn dies w√§hrend volatiler Marktphasen passiert, k√∂nnten Chancen verpasst werden ‚Äì das ist jedoch bewusst in Kauf zu nehmen gegen√ºber einem unsauberen Live-Wechsel. Wichtig ist eher, dass nach Wiederanlauf **alle Komponenten synchron** laufen, um Fehlentscheidungen zu vermeiden (z.‚ÄØB. Risk-Manager denkt, es gibt keine offenen Positionen, obwohl an der B√∂rse noch welche offen sind). Hier muss man ggf. manuell verifizieren, dass beim Neustart die internen Daten (Datenbank) mit dem tats√§chlichen B√∂rsenstatus konsistent sind.

**Umgang mit Secrets:** Wie oben erw√§hnt, sollten Secrets (API Keys, Passw√∂rter) **ausschlie√ülich √ºber Environment-Variablen** oder ein Secret-Management-Tool eingespeist werden[\[4\]]. In Docker-Compose k√∂nnen .env-Dateien benutzt werden, was bereits implementiert ist (env\_file: .env in allen relevanten Services[\[118\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L106-L114)[\[119\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L202-L210)). Nach dem Neuaufsetzen ist zu pr√ºfen, dass die .env-Datei korrekt vorliegt. Sie sollte **nicht** Teil von Backups in Klartext sein (laut Backup-Anleitung wird .env explizit ausgenommen[\[120\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L44-L48)). Beim Recovery also daran denken, die .env manuell zu sichern/verifizieren.

Alle Container laufen mit reduzierten Rechten (non-root) und zus√§tzlichen Sicherheitsoptionen (z.‚ÄØB. no-new-privileges, read\_only Dateisystem in Compose)[\[121\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L216-L224)[\[122\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L246-L254). Diese Hardening-Ma√ünahmen reduzieren die Angriffsfl√§che. Trotzdem sollte das System nur in vertrauensw√ºrdigen Netzwerken laufen und Firewalls die offenen Ports (8000-8003, 5432, 6379 etc.) absichern, vor allem wenn auf einem Cloud-Server.

**Backup-Strategie:** F√ºr Betriebssicherheit und schnelle Wiederherstellung ist ein regelm√§√üiges Backup unverzichtbar. Im Projekt gibt es eine ausf√ºhrliche *BACKUP\_ANLEITUNG.md*, die ein t√§gliches Vollbackup vorsieht. Zusammengefasst werden **jeden Tag um 3:00 Uhr** folgende Komponenten gesichert[\[123\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L30-L38)[\[124\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L50-L58):

1. *PostgreSQL-Datenbank:* Komplettes Dump aller Tabellen (Signals, Trades, Orders, Positions, Balances, Risk-Events, Metrics, Health-Checks, Strategy-Params)[\[125\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L32-L40) ‚Äì so geht keine historische Trading-Information verloren.

2. *Redis-Snapshot:* Der aktuelle Redis-In-Memory-Store (der die momentanen Topics/Zust√§nde h√§lt) wird gesichert[\[126\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L38-L41). Dies ist zwar weniger kritisch (da nach Neustart Redis leer startet und das System trotzdem funktioniert), aber f√ºr Debugging oder Replay von zuletzt publizierten Events hilfreich.

3. *Projektverzeichnis:* Der gesamte Code und die Dokumentation (alles unter dem Repository, inkl. Dockerfiles, Compose, Skripte) werden archiviert[\[127\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L42-L48). Ausgenommen sind tempor√§re/vertrauliche Dinge wie Logs, \_\_pycache\_\_, node\_modules, .git und .env[\[120\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L44-L48). Damit ist gew√§hrleistet, dass bei einem Serververlust der exakt gleiche Code wiederhergestellt werden kann ‚Äì wichtig, falls lokale √Ñnderungen vorgenommen wurden.

4. *Docker-Volumes:* Alle persistente Volumes der Container (Postgres-Datenfiles, Redis Dump, Prometheus TSDB, Grafana config) werden wegsichert[\[124\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L50-L58). Dies erlaubt notfalls auch eine punktgenaue Wiederherstellung des Zustands (z.‚ÄØB. DB-Files direkt zur√ºckspielen statt nur SQL-Import).

5. *Logs:* Alle vorhandenen Logfiles werden als ZIP archiviert[\[128\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L56-L58), um im Nachhinein Fehlerursachen analysieren zu k√∂nnen oder ein Reporting der Aktivit√§ten zu haben.

Die Backup-Anleitung beschreibt, wo diese Backups liegen (z.‚ÄØB. unter C:\\Backups\\claire\_de\_binare\\ mit Ordnern pro Datum)[\[129\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L70-L78). Beim Neuaufsetzen **nach einem Crash** sollte man zun√§chst das letzte Vollbackup einspielen:

**Recovery/Restore:** Die Schritte zur Wiederherstellung sind im Backup-Dokument skizziert[\[130\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L94-L100): *(1)* alle laufenden Container stoppen, *(2)* den Postgres-Dump (.sql) zur√ºck in die DB importieren, *(3)* den Redis RDB-Snapshot ins neue Redis-Verzeichnis legen (optional), *(4)* die Docker-Volumes (sofern im Backup als Tar/Zip) wiederherstellen, *(5)* die Container erneut starten, und *(6)* das System ausgiebig testen. Oft reicht es aber, einfach die DB mit dem Dump zu f√ºllen, da darin alle wichtigen historischen Daten stecken. Redis-Inhalt kann man meist weglassen (der f√ºllt sich wieder). Wichtig ist, dass nach dem Recovery die **Datenkonsistenz** gepr√ºft wird ‚Äì z.‚ÄØB. ob offene Trades in der DB zu real existierenden Positionen an der B√∂rse passen. Gegebenenfalls muss man hier manuell nachjustieren (im Extremfall einen Trade schlie√üen, falls die Software ihn als offen f√ºhrt, die B√∂rse aber nicht ‚Äì oder umgekehrt).

**Rollback:** Falls ein Neuaufsetzen (z.‚ÄØB. mit einer neuen Version des Bots) fehlschl√§gt oder Probleme bereitet, sollte man vorbereitet sein, auf den vorherigen Stand zur√ºckzurollen. Dazu bew√§hrt es sich, **vor dem Upgrade** ein Backup zu haben (siehe oben). Ein Rollback best√ºnde dann darin, die alte Code-Version wieder zu deployen und die vor dem Upgrade gesicherten Daten zur√ºckzuspielen. Dank Docker kann man auch versionierte Images nutzen: z.‚ÄØB. das alte Docker-Compose oder Tagged-Images der Services. Im Zweifel l√§sst sich auch nur die Datenbank r√ºckspielen, falls das Code-Update unproblematisch war, aber z.‚ÄØB. falsche Berechnungen machte ‚Äì so hat man den Stand vor dem Fehler wieder.

**Zus√§tzliche Sicherheitsma√ünahmen:** Gem√§√ü Manifest legt Claire de Binaire mehr Wert auf Sicherheit als auf maximale Profitjagd[\[131\]]. Daher sind im Betrieb einige Mechanismen aktiv, die auch beim Neuaufsetzen zu ber√ºcksichtigen sind:

* Ein **Circuit-Breaker/Not-Aus** ist integraler Bestandteil ‚Äì im UI gibt es einen Knopf, aber auch automatisch greift der Risk-Manager bei gef√§hrlichen Situationen[\[132\]][\[133\]]. Nach einem Neustart sollte dieser Mechanismus unver√§ndert aktiv sein (d.h. keine Neustart durchf√ºhren, um einen Crash-Loop nach Circuit-Breaker zu umgehen, ohne das Grundproblem zu l√∂sen). Wenn z.‚ÄØB. Tagesverlust √ºberschritten war und der Bot gestoppt wurde, sollte man bis zum n√§chsten Tag warten oder die Tagesverlust-Tracking zur√ºcksetzen, bevor man neu startet.

* **Logs & Monitoring:** Die Sicherheit umfasst auch, dass Anomalien schnell erkannt werden. Nach Neuaufsetzen unbedingt die Logs beobachten (mindestens in den ersten Stunden Live-Betrieb) und sicherstellen, dass Monitoring-Tools wie Prometheus/Grafana laufen (im Compose enthalten)[\[134\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L53-L61)[\[135\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L73-L81). Grafana kann Alerts definieren, die bei bestimmten Events Alarm schlagen.

* **Benutzerzugriff:** Sofern das Dashboard/UI mit Authentifizierung ausgestattet ist (z.‚ÄØB. 2FA, wie geplant[\[136\]]), muss beim Neuaufsetzen die User-Config √ºbernommen werden. Falls es keinen persistierten Userstore gibt (UI evtl. readonly mit Single-User), ist das weniger Thema.

Alles in allem ist ein Neuaufsetzen mit diesem Dokument und den vorhandenen Scripts gut machbar. Wichtig ist ein **sorgf√§ltiges Vorgehen** ‚Äì erst die Basisdienste, dann die Bot-Services starten; vorab Secrets kontrollieren; nachher Tests ausf√ºhren. Die vorhandenen Backup- und Sicherheitsrichtlinien sorgen daf√ºr, dass auch im Fehlerfall kein gro√üer Schaden entsteht (Daten und Geld bleiben sicher).

## 9\. Besonderheiten (ML-Modul, Shadow-Mode, essentielle Deliverables)

Zum Abschluss noch einige projektspezifische Besonderheiten, die beim Neuaufsetzen oder Betrieb bedacht werden sollten:

**ML-Modul im ‚ÄúShadow-Mode‚Äù:** Claire de Binaire ist bislang strikt regelbasiert-deterministisch, hat aber perspektivisch ein Machine-Learning-Modul als Erweiterung vorgesehen. Dieses ML-Modul (ein *ML-basierter Signal-Advisor*) soll zun√§chst in einem **Shadow Mode** laufen ‚Äì d.h. **parallel** zum eigentlichen Signalsystem, ohne direkt Trades auszul√∂sen. Konkret bedeutet das: Der ML-Service (ggf. eigener Microservice) w√ºrde die gleichen Marktdaten bekommen und eigene **ML-Signale** generieren, diese aber auf einen separaten Topic, z.‚ÄØB. ml\_signals, publizieren[\[137\]]. Der Risk-Manager oder ein √ºbergeordnetes Modul k√∂nnte diese ML-Signale zwar auswerten, aber nicht direkt ausf√ºhren, sondern h√∂chstens zur Best√§tigung oder Alarmierung nutzen. So kann man die Leistung des ML-Modells beobachten, ohne das deterministische Kernsystem zu gef√§hrden.

Beim Neuaufsetzen muss man beachten, dass ein ML-Modul (falls bereits integriert) **zus√§tzliche Ressourcen** erfordert ‚Äì z.‚ÄØB. ein geladenes ML-Modell, m√∂glicherweise eine GPU oder spezielle Python-Dependencies (TensorFlow/PyTorch etc.). Diese m√ºssen im Deployment-Stack ber√ºcksichtigt sein (Docker-Image mit ML-Library, evtl. gr√∂√üeres Memory). Im aktuellen Projektstadium ist das ML-Modul laut Roadmap optional und nicht aktiv im Trading-Prozess[\[137\]]. Sollte es zum Einsatz kommen, sind auch hier Transparenz und Nachvollziehbarkeit Pflicht: Entscheidungen des ML m√ºssen geloggt und erkl√§rbar sein. ‚ÄúShadow-Mode‚Äù bedeutet auch, dass man **Metriken erhebt**, wie oft das ML-Modell zustimmt oder abweicht von der Regel-Engine, und diese Ergebnisse in Berichten dokumentiert. Es liegt ein Konzeptpapier vor, das genau diese Integration beleuchtet und Deliverables definiert (z.‚ÄØB. einen ausf√ºhrlichen Bericht mit Entscheidungsgrundlagen, Modellvergleich etc.). F√ºr den operativen Betrieb hei√üt das: Das ML-Modul darf **keine automatische Trade-Befugnis** haben, bevor nicht in solchen Berichten nachgewiesen wurde, dass es sicher und vorteilhaft ist ‚Äì es bleibt im read-only Modus in der Produktion, bis ein Go entschieden wird. Dies entspricht dem Leitprinzip, dass die deterministische Nachvollziehbarkeit gewahrt bleiben muss, egal wie ‚Äúsmart‚Äù das ML-Modell ist[\[138\]][\[139\]].

**Essenzielle Deliverables f√ºr Betriebssicherheit & Transparenz:** √úber die reine Codebasis hinaus lebt Claire de Binaire von umfangreicher Dokumentation und Auditierbarkeit. Einige Artefakte, die f√ºr einen sicheren, transparenten Betrieb und eine schnelle Wiederinbetriebnahme essenziell sind:

* **ARCHITEKTUR.md:** Das Architektur-Doc ist die *Single Source of Truth* f√ºr das Systemdesign[\[140\]]. Beim Neuaufsetzen dient es als Referenz f√ºr alle Komponenten, Schnittstellen, Env-Variablen und Healthchecks. Jede √Ñnderung am System sollte hier nachvollzogen werden. Es gew√§hrleistet, dass alle Teammitglieder und auch zuk√ºnftige Maintainer schnell verstehen, wie die Teile zusammenspielen.

* **EVENT\_SCHEMA.json:** Das formale JSON-Schema der Events stellt sicher, dass Produzenten und Konsumenten dieselben Datenformate nutzen. Es erh√∂ht die Transparenz, weil es quasi die ‚ÄúVertr√§ge‚Äù zwischen den Services dokumentiert. Beim Debugging kann man damit valide von invalide Events unterscheiden. Zudem unterst√ºtzt es die Auditierbarkeit: Man k√∂nnte eingehende und ausgehende Events gegen das Schema pr√ºfen, um Fehler fr√ºh zu erkennen.

* **Risikomanagement-Dokumentation:** Eine klare Beschreibung aller Risikoregeln (wie in *Risikomanagement-Logik.md* und ARCHITEKTUR.md) ist f√ºr die **Betriebssicherheit** fundamental. So ist f√ºr jeden Eingriff des Bots definiert, warum er erfolgt. Diese Dokumente dienen intern als Referenz und extern ggf. als Nachweis gegen√ºber Dritten, dass kontrolliert und konservativ gehandelt wird. √Ñnderungen an Risikoparametern sollten hier dokumentiert werden, um Transparenz zu wahren.

* **Logging & Audit-Trails:** Das System ist so gebaut, dass **jede Entscheidung erkl√§rbar** ist ‚Äì nicht nur durch Code, sondern durch Logs[\[141\]]. Die strukturierte Speicherung von Signalen, Entscheidungen und Trades in der DB erm√∂glicht es, im Nachhinein jeden Trade zu begr√ºnden (‚Äûwegen Signal X mit Grund Y, gepr√ºft gegen Limit Z‚Äú). Diese Audit-Trails sind ein deliverable in dem Sinne, dass sie jederzeit vorgezeigt werden k√∂nnen, um das Verhalten des Bots zu pr√ºfen. Im Betrieb sollten regelm√§√üige Auswertungen der Logs/DB (z.‚ÄØB. w√∂chentliche Reports der Performance und Regel-Compliance) erfolgen, um fr√ºhzeitig Auff√§lligkeiten zu erkennen.

* **Backup- und Recovery-Prozesse:** Die oben erw√§hnten Backup-Skripte und Anleitungen sind ein essenzieller Bestandteil der Betriebsdokumentation. Sie stellen sicher, dass ein **Wiederanlauf** nach Ausf√§llen m√∂glich ist, ohne Datenverlust. Das Vorhandensein getesteter Backup-Dateien und einer klaren Recovery-Doku (Schritt-f√ºr-Schritt) ist entscheidend, um im Ernstfall schnell reagieren zu k√∂nnen. Diese m√ºssen gepflegt und aktuell gehalten werden (z.‚ÄØB. Anpassung falls neue Volumes/Services hinzukommen).

* **Testdokumentation (End-to-End Guide):** Ein weiterer wichtiger deliverable ist der vollst√§ndige End-to-End-Testplan. Er gew√§hrleistet, dass nach jeder Neuinstallation oder √Ñnderung das System auf Herz und Nieren gepr√ºft wird. F√ºr Betriebssicherheit ist es unerl√§sslich, einen solchen Validierungsprozess zu haben ‚Äì er verhindert, dass ein fehlerhaft konfiguriertes System live geht.

* **Entscheidungs- und √Ñnderungsprotokolle:** Im Projekt werden Architektur-Entscheidungen (ADR) und √Ñnderungen dokumentiert (z.‚ÄØB. DECISION\_LOG.md, CHANGELOGs). Diese erh√∂hen die Transparenz f√ºr alle Beteiligten: Man kann nachvollziehen, warum z.‚ÄØB. von SQLite auf PostgreSQL gewechselt wurde, warum Telegram entfernt wurde (ADR-003) etc. Beim Neuaufsetzen kann man hier nachlesen, was aktuell gelten sollte.

Abschlie√üend l√§sst sich sagen, dass Claire de Binaire gro√üen Wert auf **technische Eleganz, Integrit√§t und Nachvollziehbarkeit** legt ‚Äì wie im Manifest festgehalten[\[142\]]. Beim Neuaufsetzen profitiert man davon: Eine gute Dokumentation, klar strukturierte Services und ein robustes Deployment-Setup sorgen daf√ºr, dass der Bot schnell wieder zum Laufen gebracht werden kann. Indem man den oben beschriebenen Leitf√§den folgt, stellt man sicher, dass der **Betrieb sicher** (durch strenge Risk-Limits, keine Leaks), **transparent** (durch Dokumentation und Logging) und **wiederanlauf-f√§hig** (durch Backups und klare Prozesse) bleibt ‚Äì selbst wenn der Server mal komplett neu aufgesetzt werden muss.

---

[\[1\]] [\[51\]] [\[75\]] [\[76\]] [\[90\]] [\[91\]] [\[97\]] [\[98\]] [\[99\]] [\[100\]] [\[101\]] [\[102\]] [\[103\]] [\[104\]] [\[105\]] [\[106\]] [\[107\]] [\[108\]] [\[109\]] [\[110\]] [\[111\]] [\[115\]] [\[116\]] END\_TO\_END\_TEST\_GUIDE.md

\1

[\[2\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L28-L36) [\[3\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L9-L17) [\[6\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L13-L19) [\[8\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L32-L40) [\[11\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L178-L186) [\[18\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L16-L24) [\[19\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L38-L44) [\[20\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L236-L244) [\[24\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L112-L119) [\[25\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L206-L214) [\[26\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L24-L27) [\[27\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L252-L255) [\[28\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L16-L19) [\[29\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L36-L40) [\[118\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L106-L114) [\[119\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L202-L210) [\[121\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L216-L224) [\[122\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L246-L254) [\[134\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L53-L61) [\[135\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L73-L81) docker-compose.yml

[https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml)

[\[4\]] [\[5\]] [\[9\]] [\[10\]] [\[22\]] [\[31\]] [\[47\]] [\[48\]] [\[70\]] [\[94\]] [\[136\]] [\[137\]] ARCHITEKTUR.md

\1

[\[7\]] [\[15\]] [\[33\]] [\[34\]] [\[74\]] [\[114\]] SIGNAL\_ENGINE\_COMPLETE.md

\1

[\[12\]] [\[13\]] [\[14\]] [\[95\]] [\[96\]] [\[112\]] [\[113\]] CODE\_CLEANUP\_AUDIT.md

\1

[\[16\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L14-L19) [\[17\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L20-L23) [\[21\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L9-L16) [\[23\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L14-L22) Dockerfile

[https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk\_manager/Dockerfile](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile)

[\[30\]] [\[32\]] [\[35\]] [\[37\]] [\[40\]] [\[41\]] [\[42\]] [\[43\]] [\[44\]] [\[45\]] [\[46\]] [\[49\]] [\[50\]] [\[65\]] [\[66\]] [\[67\]] [\[68\]] [\[69\]] [\[92\]] [\[93\]] Service-Kommunikation & Datenfl√ºsse.md

\1

[\[36\]] [\[38\]] [\[39\]] [\[77\]] [\[78\]] [\[79\]] [\[80\]] [\[81\]] [\[82\]] [\[83\]] [\[84\]] [\[85\]] [\[86\]] [\[87\]] [\[88\]] [\[89\]] [\[132\]] [\[133\]] Risikomanagement-Logik.md

\1

[\[52\]] [\[53\]] [\[54\]] [\[55\]] [\[56\]] [\[57\]] [\[58\]] [\[59\]] [\[60\]] [\[61\]] [\[62\]] [\[63\]] DATABASE\_SCHEMA.sql

\1

[\[64\]] [\[71\]] EVENT\_SCHEMA.json

\1

[\[72\]] [\[73\]] SERVICE\_TEMPLATE.md

\1

[\[117\]] [\[131\]] [\[140\]] [\[141\]] [\[142\]] MANIFEST.md

\1

[\[120\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L44-L48) [\[123\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L30-L38) [\[124\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L50-L58) [\[125\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L32-L40) [\[126\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L38-L41) [\[127\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L42-L48) [\[128\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L56-L58) [\[129\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L70-L78) [\[130\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L94-L100) BACKUP\_ANLEITUNG.md

[https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP\_ANLEITUNG.md](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md)

[\[138\]] [\[139\]] Briefing\_ ML-basierter Signal-Advisor im deterministischen Handelssystem \_Claire de Binaire\_.pdf

\1